# integrations/historical_data_loader.py
import logging
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from pathlib import Path
from core.database.database import Instrument,Candle
from utils.datetime_utils import now_utc, utc_from_days_ago, utc_from_minutes_ago, ensure_timezone_aware, days_between_utc
from .tinkoff_integration import TinkoffIntegration
from core.database import Database
from sqlalchemy import func

logger = logging.getLogger(__name__)

class HistoricalDataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Tinkoff API –≤ –±–∞–∑—É"""
    
    def __init__(self, db: Database, tinkoff_client: TinkoffIntegration):
        self.db = db
        self.tinkoff = tinkoff_client
        self.mapping_file = Path("instruments_mapping.json")
        
    async def load_instruments_mapping(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        try:
            if self.mapping_file.exists():
                with open(self.mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
                    logger.info(f"üìã Loaded {len(mapping['instruments'])} instruments from mapping")
                    return mapping
            else:
                logger.warning("‚ö†Ô∏è Instruments mapping file not found, creating from API...")
                return await self.create_instruments_mapping()
                
        except Exception as e:
            logger.error(f"‚ùå Error loading instruments mapping: {e}")
            return {"instruments": {}}
    
    async def create_instruments_mapping(self) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ API"""
        popular_instruments = await self.tinkoff.get_popular_instruments()
        
        mapping = {
            "description": "Auto-generated mapping from Tinkoff API",
            "last_updated": datetime.now().isoformat(),
            "instruments": {}
        }
        
        for instrument in popular_instruments:
            mapping["instruments"][instrument["ticker"]] = {
                "figi": instrument["figi"],
                "name": instrument["name"],
                "type": instrument["type"],
                "currency": instrument["currency"]
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥
        try:
            with open(self.mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping, f, indent=2, ensure_ascii=False)
            logger.info(f"üíæ Saved instruments mapping to {self.mapping_file}")
        except Exception as e:
            logger.error(f"‚ùå Error saving mapping: {e}")
        
        return mapping
    
    async def sync_instruments_to_database(self) -> int:
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            mapping = await self.load_instruments_mapping()
            synced_count = 0
            
            for ticker, info in mapping.get("instruments", {}).items():
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥ Database
                    figi = self.db.save_instrument(
                        figi=info["figi"],
                        ticker=ticker,
                        name=info["name"],
                        instrument_type=info.get("type", "share")
                    )
                    
                    if figi:
                        synced_count += 1
                        logger.info(f"‚úÖ Synced instrument: {ticker} ({info['name']})")
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to sync instrument: {ticker}")
                        
                except Exception as e:
                    logger.error(f"‚ùå Error syncing {ticker}: {e}")
            
            logger.info(f"üìä Synced {synced_count} instruments to database")
            return synced_count
            
        except Exception as e:
            logger.error(f"‚ùå Error syncing instruments: {e}")
            return 0

    async def load_historical_candles(
        self,
        ticker: str,
        interval: str = "5min", 
        days_back: int = 30,
        force_reload: bool = False
    ) -> Dict:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–≤–µ—á–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞
        
        Args:
            ticker: –¢–∏–∫–µ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "SBER")
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π ("1min", "5min", "hour", "day")  
            days_back: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            force_reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ (–æ—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ)
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ —á–µ—Ä–µ–∑ –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥
            instrument = self.db.get_instrument_by_ticker(ticker)
            if not instrument:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ API –∏ –¥–æ–±–∞–≤–∏—Ç—å –≤ –±–∞–∑—É
                api_instrument = await self.tinkoff.find_instrument_by_ticker(ticker)
                if not api_instrument:
                    return {
                        "success": False,
                        "error": f"Instrument {ticker} not found",
                        "loaded_candles": 0
                    }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤ –±–∞–∑—É
                self.db.save_instrument(
                    figi=api_instrument["figi"],
                    ticker=ticker,
                    name=api_instrument["name"],
                    instrument_type=api_instrument.get("type", "share")
                )
                
                instrument = {"figi": api_instrument["figi"]}
            
            figi = instrument["figi"]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥
            if not force_reload:
                existing_candles = self.db.get_candles(
                    figi=figi,
                    interval=interval,
                    limit=10
                )
                
                if existing_candles:
                    logger.info(f"üìä Found {len(existing_candles)} existing candles for {ticker}")
                    
                    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å –∫–∞–∫–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å
                    # –í—Å–µ –¥–∞—Ç—ã –∏–∑ –ë–î —É–∂–µ timezone-aware (UTC)
                    last_candle_time = max(candle['time'] for candle in existing_candles)
                    last_candle_time = ensure_timezone_aware(last_candle_time)  # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                    
                    from_time = last_candle_time + timedelta(minutes=1)
                    to_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: timezone-aware
                    
                    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ timezone-aware –¥–∞—Ç
                    if from_time >= to_time:
                        return {
                            "success": True,
                            "message": "Data is up to date",
                            "loaded_candles": 0,
                            "existing_candles": len(existing_candles)
                        }
                else:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–µ—Ä–∏–æ–¥
                    from_time = utc_from_days_ago(days_back)  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                    to_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            else:
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ - –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥
                from_time = utc_from_days_ago(days_back)  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                to_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ—á–∏ —á–µ—Ä–µ–∑ API
            logger.info(f"üìà Loading {interval} candles for {ticker} from {from_time.date()} to {to_time.date()}")
            
            candles_data = await self.tinkoff.get_candles(
                figi=figi,
                interval=interval,
                from_time=from_time,
                to_time=to_time
            )
            
            if not candles_data:
                return {
                    "success": False,
                    "error": "No candles received from API",
                    "loaded_candles": 0
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–µ—á–∏ –≤ –±–∞–∑—É —á–µ—Ä–µ–∑ –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥
            result = self.db.save_candles(candles_data, figi=figi, interval=interval)
            
            if result.get('saved', 0) > 0:
                logger.info(f"‚úÖ Successfully loaded {len(candles_data)} candles for {ticker}")
                return {
                    "success": True,
                    "ticker": ticker,
                    "interval": interval,
                    "loaded_candles": len(candles_data),
                    "period": f"{from_time.date()} - {to_time.date()}"
                }
            else:
                return {
                    "success": False,
                    "error": "Failed to save candles to database",
                    "loaded_candles": 0
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error loading historical candles for {ticker}: {e}")
            return {
                "success": False,
                "error": str(e),
                "loaded_candles": 0
            }

    async def bulk_load_popular_instruments(
        self,
        interval: str = "5min",
        days_back: int = 30,
        max_concurrent: int = 3
    ) -> Dict:
        """
        –ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        
        Args:
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π
            days_back: –î–Ω–µ–π –Ω–∞–∑–∞–¥
            max_concurrent: –ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫
        """
        try:
            mapping = await self.load_instruments_mapping()
            popular_tickers = list(mapping.get("demo_signals", {}).get("most_traded", []))
            
            if not popular_tickers:
                popular_tickers = ["SBER", "GAZP", "LKOH", "YNDX", "VTBR"]
            
            logger.info(f"üöÄ Starting bulk load for {len(popular_tickers)} instruments")
            
            results = {
                "completed": [],
                "failed": [],
                "total_candles": 0,
                "total_requested": len(popular_tickers),
                "start_time": now_utc().isoformat(),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            }
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è concurrent –∑–∞–ø—Ä–æ—Å–æ–≤
            semaphore = asyncio.Semaphore(max_concurrent)
            
            async def load_single_ticker(ticker):
                async with semaphore:
                    result = await self.load_historical_candles(
                        ticker=ticker,
                        interval=interval,
                        days_back=days_back
                    )
                    
                    if result["success"]:
                        results["completed"].append(result)
                        results["total_candles"] += result["loaded_candles"]
                    else:
                        results["failed"].append({
                            "ticker": ticker,
                            "error": result["error"]
                        })
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–≥—Ä—É–∑–∫–∞–º–∏
                    await asyncio.sleep(1)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
            tasks = [load_single_ticker(ticker) for ticker in popular_tickers]
            await asyncio.gather(*tasks, return_exceptions=True)
            
            results["end_time"] = now_utc().isoformat()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            results["duration_minutes"] = (
                datetime.fromisoformat(results["end_time"].replace('Z', '+00:00')) - 
                datetime.fromisoformat(results["start_time"].replace('Z', '+00:00'))
            ).total_seconds() / 60
            
            logger.info(f"üìä Bulk load completed: {len(results['completed'])}/{len(popular_tickers)} successful")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Error in bulk load: {e}")
            return {
                "error": str(e),
                "completed": [],
                "failed": [],
                "total_candles": 0,
                "end_time": now_utc().isoformat()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            }
    
    async def get_data_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            with self.db.get_session() as session:
                # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                total_instruments = session.query(Instrument).count()
                total_candles = session.query(Candle).count()
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
                instruments = session.query(Instrument).limit(10).all()
                instruments_info = []
                
                for instrument in instruments:
                    candles_count = session.query(Candle).filter(
                        Candle.figi == instrument.figi
                    ).count()
                    
                    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–≤–µ—á—É —Å timezone-aware —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º
                    latest_candle = session.query(Candle).filter(
                        Candle.figi == instrument.figi
                    ).order_by(Candle.time.desc()).first()
                    
                    latest_time = None
                    if latest_candle:
                        latest_time = ensure_timezone_aware(latest_candle.time).isoformat()
                    
                    instruments_info.append({
                        "ticker": instrument.ticker,
                        "figi": instrument.figi,
                        "name": instrument.name,
                        "candles_count": candles_count,
                        "latest_candle": latest_time
                    })
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–≤–µ—á–∞–º
                candles_info = []
                candles_by_figi = session.query(
                    Candle.figi, 
                    func.count(Candle.id).label('count')
                ).group_by(Candle.figi).limit(10).all()
                
                for figi, count in candles_by_figi:
                    instrument = session.query(Instrument).filter(
                        Instrument.figi == figi
                    ).first()
                    
                    candles_info.append({
                        "figi": figi,
                        "ticker": instrument.ticker if instrument else "Unknown",
                        "candles_count": count
                    })
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
                intervals = session.query(Candle.interval).distinct().all()
                available_intervals = [interval[0] for interval in intervals]
                
                return {
                    "total_instruments": total_instruments,
                    "total_candles": total_candles,
                    "sample_instruments": instruments_info,
                    "candles_by_instrument": candles_info,
                    "available_intervals": available_intervals,
                    "status_timestamp": now_utc().isoformat(),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                    "status": "operational"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error getting data status: {e}")
            return {
                "error": str(e),
                "status": "error",
                "status_timestamp": now_utc().isoformat()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            }
    
    def _get_instruments_detailed_stats(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º"""
        instruments_info = []
        
        try:
            with self.db.session() as session:
                from core.database import Instrument, Candle
                from sqlalchemy import func
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
                instruments_stats = session.query(
                    Instrument.ticker,
                    Instrument.name,
                    func.count(Candle.id).label('candles_count'),
                    func.max(Candle.time).label('last_candle'),
                    func.min(Candle.time).label('first_candle')
                ).outerjoin(
                    Candle, Instrument.figi == Candle.instrument_id
                ).group_by(
                    Instrument.ticker, Instrument.name
                ).all()
                
                for stat in instruments_stats:
                    instruments_info.append({
                        "ticker": stat.ticker,
                        "name": stat.name,
                        "candles_count": stat.candles_count,
                        "last_candle": stat.last_candle.isoformat() if stat.last_candle else None,
                        "first_candle": stat.first_candle.isoformat() if stat.first_candle else None,
                        "has_data": stat.candles_count > 0
                    })
        except Exception as e:
            logger.error(f"‚ùå Error getting instruments stats: {e}")
        
        return instruments_info
    
    async def cleanup_old_data(self, days_to_keep: int = 90) -> Dict:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            with self.db.session() as session:
                from core.database import Candle
                
                # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ
                old_records = session.query(Candle).filter(
                    Candle.time < cutoff_date
                ).count()
                
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
                deleted = session.query(Candle).filter(
                    Candle.time < cutoff_date
                ).delete()
                
                logger.info(f"üóëÔ∏è Cleaned up {deleted} old candle records (older than {cutoff_date.date()})")
                
                return {
                    "success": True,
                    "deleted_records": deleted,
                    "cutoff_date": cutoff_date.isoformat(),
                    "days_kept": days_to_keep
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error cleaning up old data: {e}")
            return {
                "success": False,
                "error": str(e)
            }
        
    def _deduplicate_candles_data(self, candles_data: List[Dict], figi: str, interval: str) -> List[Dict]:
        """
        –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
        
        Args:
            candles_data: –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π –æ—Ç Tinkoff API
            figi: FIGI –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            interval: –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π
            
        Returns:
            List[Dict]: –æ—á–∏—â–µ–Ω–Ω—ã–µ –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã–µ
        """
        if not candles_data:
            return candles_data
        
        seen_times = set()
        deduplicated = []
        duplicates_count = 0
        
        for candle in candles_data:
            candle_time = candle['time']
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
            time_key = (figi, interval, candle_time)
            
            if time_key not in seen_times:
                seen_times.add(time_key)
                deduplicated.append(candle)
            else:
                duplicates_count += 1
                logger.warning(f"‚ö†Ô∏è Removing duplicate candle for {figi} at {candle_time}")
        
        if duplicates_count > 0:
            logger.info(f"üßπ Removed {duplicates_count} duplicate candles from {len(candles_data)} total")
        
        return deduplicated

    # –î–æ–±–∞–≤–∏—Ç—å –≤ integrations/tinkoff_integration.py

    def _validate_candles_data(self, candles: List[Dict]) -> List[Dict]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –æ—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π –æ—Ç API
        
        Args:
            candles: —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç Tinkoff API
            
        Returns:
            List[Dict]: –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        valid_candles = []
        
        for i, candle in enumerate(candles):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                required_fields = ['time', 'open', 'high', 'low', 'close']
                if not all(field in candle for field in required_fields):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: missing required fields")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å —Ü–µ–Ω
                open_price = float(candle['open'])
                high_price = float(candle['high'])
                low_price = float(candle['low'])
                close_price = float(candle['close'])
                
                if not (low_price <= open_price <= high_price and 
                    low_price <= close_price <= high_price):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: invalid OHLC values")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ü–µ–Ω—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                if any(price <= 0 for price in [open_price, high_price, low_price, close_price]):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: negative or zero prices")
                    continue
                
                valid_candles.append(candle)
                
            except (ValueError, TypeError) as e:
                logger.warning(f"‚ö†Ô∏è Skipping candle {i}: validation error {e}")
                continue
        
        logger.info(f"‚úÖ Validated {len(valid_candles)}/{len(candles)} candles")
        return valid_candles
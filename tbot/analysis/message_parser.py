import re
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from uuid import UUID

from .pattern_manager import PatternManager
from .consensus_detector import get_consensus_detector

logger = logging.getLogger(__name__)

@dataclass
class ParseResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    success: bool
    signal_data: Optional[Dict] = None
    error: Optional[str] = None
    confidence: float = 0.0


class MessageParser:
    """–ü–∞—Ä—Å–µ—Ä —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ –ë–î"""
    
    VERSION = "3.1.0"
    
    def __init__(self, db_manager=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
        
        Args:
            db_manager: Database instance –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ –ë–î
        """
        self.db_manager = db_manager
        
        if db_manager:
            self.pattern_manager = PatternManager(db_manager)
            logger.info(f"MessageParser v{self.VERSION} initialized with PatternManager (DB mode)")
        else:
            self.pattern_manager = None
            logger.warning(f"MessageParser v{self.VERSION} initialized WITHOUT database")
    
    def reload_patterns(self):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –ë–î"""
        if self.pattern_manager:
            self.pattern_manager.reload_patterns()
            logger.info("Patterns reloaded from database")
        else:
            logger.warning("Cannot reload patterns - no database connection")
    
    def parse_raw_message(self, raw_message: Dict) -> ParseResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            raw_message: —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            ParseResult: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        try:
            text = raw_message.get('text', '')
            if not text or not text.strip():
                return ParseResult(success=False, error="Empty message text")
            
            logger.debug(f"üìù Parsing message {raw_message.get('id')}")
            logger.debug(f"Original text: {text[:200]}")
            
            # –ò–ó–í–õ–ï–ö–ê–ï–ú –ê–í–¢–û–†–ê –ò–ó –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û –¢–ï–ö–°–¢–ê (–î–û –û–ß–ò–°–¢–ö–ò!)
            author = self._extract_author(text, raw_message.get('author_username'))
            logger.debug(f"üë§ Extracted author: {author}")
            
            # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è —Ö–µ—à—Ç–µ–≥–æ–≤
            cleaned_text = text.strip()
            
            if not self._is_trading_message(cleaned_text):
                return ParseResult(success=False, error="Not a trading message")
            
            ticker = self._extract_ticker(cleaned_text)
            if not ticker:
                return ParseResult(success=False, error="No ticker found")
            
            operation_type, direction = self._analyze_operation(cleaned_text)
            
            prices = self._extract_prices(cleaned_text)
            confidence = self._calculate_confidence(cleaned_text, ticker, direction, operation_type)
            
            signal_data = {
                'raw_message_id': raw_message['id'],
                'parser_version': self.VERSION,
                'timestamp': raw_message['timestamp'],
                'channel_id': raw_message['channel_id'],
                'author': author,
                'original_text': text,
                'ticker': ticker,
                'direction': direction,
                'signal_type': operation_type,
                'target_price': prices.get('target'),
                'stop_loss': prices.get('stop_loss'),
                'take_profit': prices.get('take_profit'),
                'confidence_score': confidence,
                'extracted_data': {
                    'cleaned_text': cleaned_text,
                    'operation_analysis': self._debug_operation_analysis(cleaned_text),
                    'all_tickers': self._extract_all_tickers(cleaned_text),
                    'all_prices': self._extract_all_numbers(cleaned_text),
                    'raw_message_id': raw_message['id']
                }
            }
            
            logger.info(f"‚úÖ Parsed message {raw_message['id']}: "
                       f"ticker={ticker}, direction={direction}, operation={operation_type}, "
                       f"author={author}, confidence={confidence}")
            
            return ParseResult(success=True, signal_data=signal_data, confidence=confidence)
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing message {raw_message.get('id')}: {e}", exc_info=True)
            return ParseResult(success=False, error=f"Exception: {str(e)}")
    
    def _clean_message_text(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ –º—É—Å–æ—Ä–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
        –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–ê –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        
        Args:
            text: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            str: –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not self.pattern_manager:
            return text.strip()
        
        cleaned = text
        
        # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        # garbage_patterns = self.pattern_manager.get_patterns('garbage')
        # for pattern in garbage_patterns:
        #     cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
        
        cleaned = re.sub(r'\n\s*\n', '\n', cleaned)
        cleaned = cleaned.strip()
        
        return cleaned
    
    def _is_trading_message(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã–º
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            bool: True –µ—Å–ª–∏ —Ç–æ—Ä–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        if not self.pattern_manager:
            return False
        
        trading_keywords = self.pattern_manager.get_patterns('trading_keyword')
        ticker_patterns = self.pattern_manager.get_patterns('ticker')
        
        has_keywords = any(re.search(pattern, text, re.IGNORECASE) for pattern in trading_keywords)
        has_ticker = any(re.search(pattern, text) for pattern in ticker_patterns)
        
        trading_emojis = ['üî•', 'üé™', 'üìà', 'üìâ', '‚≠ê']
        has_emoji = any(emoji in text for emoji in trading_emojis)
        
        result = has_keywords or has_ticker or has_emoji
        
        logger.debug(f"Trading check: keywords={has_keywords}, ticker={has_ticker}, "
                    f"emoji={has_emoji} -> {result}")
        
        return result
    
    def _extract_ticker(self, text: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–∫–µ—Ä–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Optional[str]: –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–∏–∫–µ—Ä –∏–ª–∏ None
        """
        if not self.pattern_manager:
            return None
        
        ticker_patterns = self.pattern_manager.get_patterns('ticker')
        
        for pattern in ticker_patterns:
            match = re.search(pattern, text)
            if match:
                ticker = match.group(1).upper()
                logger.debug(f"Found ticker: {ticker} with pattern: {pattern}")
                return ticker
        
        return None
    
    def _extract_all_tickers(self, text: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            List[str]: —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤
        """
        if not self.pattern_manager:
            return []
        
        ticker_patterns = self.pattern_manager.get_patterns('ticker')
        
        tickers = set()
        for pattern in ticker_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                ticker = match.upper()
                if 3 <= len(ticker) <= 6 and ticker.isalpha():
                    if ticker not in ['VIP', 'BOT', 'NEW', 'TOP', 'WIN', 'BUY', 'SELL']:
                        tickers.add(ticker)
        
        return list(tickers)
    
    def _analyze_operation(self, text: str) -> Tuple[str, str]:
        """
        –ê–Ω–∞–ª–∏–∑ –æ–ø–µ—Ä–∞—Ü–∏–∏ - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Tuple[str, str]: (operation_type, direction)
                operation_type: 'entry' | 'exit' | 'update'
                direction: 'long' | 'short' | 'mixed'
        """
        if not self.pattern_manager:
            return 'entry', 'mixed'
        
        exit_patterns = self.pattern_manager.get_patterns('operation_exit')
        
        for pattern in exit_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                logger.debug(f"Found exit pattern: {pattern} -> {match.group()}")
                
                if re.search(r'(?i)(–ª–æ–Ω–≥|long)', match.group()):
                    return 'exit', 'long'
                elif re.search(r'(?i)(—à–æ—Ä—Ç|short)', match.group()):
                    return 'exit', 'short'
                else:
                    return 'exit', 'mixed'
        
        long_patterns = self.pattern_manager.get_patterns('direction_long')
        short_patterns = self.pattern_manager.get_patterns('direction_short')
        
        for pattern in long_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                logger.debug(f"Found long entry pattern: {pattern}")
                return 'entry', 'long'
        
        for pattern in short_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                logger.debug(f"Found short entry pattern: {pattern}")
                return 'entry', 'short'
        
        if re.search(r'(?i)\b(–ª–æ–Ω–≥|long)\b', text):
            return 'entry', 'long'
        elif re.search(r'(?i)\b(—à–æ—Ä—Ç|short)\b', text):
            return 'entry', 'short'
        
        return 'entry', 'mixed'
    
    def _debug_operation_analysis(self, text: str) -> Dict:
        """
        –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–ø–µ—Ä–∞—Ü–∏–π
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Dict: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        """
        if not self.pattern_manager:
            return {}
        
        debug_info = {
            'exit_matches': [],
            'long_matches': [],
            'short_matches': [],
            'direction_words': []
        }
        
        exit_patterns = self.pattern_manager.get_patterns('operation_exit')
        for pattern in exit_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                debug_info['exit_matches'].append({'pattern': pattern, 'matches': matches})
        
        long_patterns = self.pattern_manager.get_patterns('direction_long')
        for pattern in long_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                debug_info['long_matches'].append({'pattern': pattern, 'matches': matches})
        
        short_patterns = self.pattern_manager.get_patterns('direction_short')
        for pattern in short_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                debug_info['short_matches'].append({'pattern': pattern, 'matches': matches})
        
        direction_words = re.findall(r'(?i)\b(–ª–æ–Ω–≥|—à–æ—Ä—Ç|long|short)\b', text)
        debug_info['direction_words'] = direction_words
        
        return debug_info
    
    def _extract_author(self, text: str, fallback: Optional[str] = None) -> str:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            fallback: –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
        Returns:
            str: –∏–º—è –∞–≤—Ç–æ—Ä–∞
        """
        if not self.pattern_manager:
            logger.warning("‚ö†Ô∏è No pattern_manager in _extract_author")
            return fallback or 'Unknown'
        
        author_patterns = self.pattern_manager.get_patterns('author')
        
        logger.debug(f"üîç Author patterns count: {len(author_patterns)}")
        logger.debug(f"üîç Text to search (first 150 chars): {text[:150]}")
        
        for i, pattern in enumerate(author_patterns):
            logger.debug(f"üîç Testing author pattern #{i+1}: {pattern}")
            try:
                match = re.search(pattern, text)
                if match:
                    # –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –ø–µ—Ä–≤—É—é –≥—Ä—É–ø–ø—É, –µ—Å–ª–∏ –µ—Å—Ç—å
                    if match.groups():
                        author = match.group(1)
                    else:
                        author = match.group()
                    
                    logger.info(f"‚úÖ Found author: '{author}' with pattern: {pattern}")
                    return author
                else:
                    logger.debug(f"‚ùå Pattern #{i+1} did not match")
            except Exception as e:
                logger.error(f"‚ùå Error testing pattern {pattern}: {e}")
                continue
        
        logger.warning(f"‚ö†Ô∏è No author found in text, using fallback: {fallback or 'Unknown'}")
        return fallback or 'Unknown'
    
    def _extract_prices(self, text: str) -> Dict[str, Optional[float]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Dict: —Å–ª–æ–≤–∞—Ä—å —Å —Ü–µ–Ω–∞–º–∏
        """
        prices = {'target': None, 'stop_loss': None, 'take_profit': None}
        
        if not self.pattern_manager:
            return prices
        
        target_patterns = self.pattern_manager.get_patterns('price_target')
        stop_patterns = self.pattern_manager.get_patterns('price_stop')
        take_patterns = self.pattern_manager.get_patterns('price_take')
        
        price_pattern_groups = {
            'target': target_patterns,
            'stop_loss': stop_patterns,
            'take_profit': take_patterns
        }
        
        for price_type, patterns in price_pattern_groups.items():
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    try:
                        price_str = match.group(1) if match.groups() else match.group()
                        price = float(price_str.replace(',', '.'))
                        if 0.01 <= price <= 100000:
                            prices[price_type] = price
                            break
                    except (ValueError, IndexError):
                        continue
        
        return prices
    
    def _extract_all_numbers(self, text: str) -> List[float]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö —á–∏—Å–µ–ª –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            List[float]: —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª
        """
        numbers = []
        for match in re.finditer(r'\d+(?:[.,]\d+)?', text):
            try:
                number = float(match.group().replace(',', '.'))
                if 0.01 <= number <= 100000:
                    numbers.append(number)
            except ValueError:
                continue
        return numbers
    
    def _calculate_confidence(self, text: str, ticker: str, direction: str, operation: str) -> float:
        """
        –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø–∞—Ä—Å–∏–Ω–≥–µ
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            ticker: –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–∏–∫–µ—Ä
            direction: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            operation: —Ç–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            float: —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0.0 - 1.0)
        """
        confidence = 0.0
        
        if ticker:
            confidence += 0.4
        if direction and direction != 'mixed':
            confidence += 0.3
        if operation:
            confidence += 0.2
        
        if len(text.split()) > 3:
            confidence += 0.05
        if any(keyword in text.lower() for keyword in ['—Å–¥–µ–ª–∫–∞', '–ø–æ–∑–∏—Ü–∏—è', '—Å–∏–≥–Ω–∞–ª']):
            confidence += 0.05
        
        return min(confidence, 1.0)


class MessageParsingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""

    def __init__(self, db_manager, parser: MessageParser = None):
        """
        Args:
            db_manager: Database instance
            parser: MessageParser instance (—Å–æ–∑–¥–∞—Å—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω)
        """
        self.db = db_manager
        self.parser = parser or MessageParser(db_manager)
        self.consensus_detector = get_consensus_detector(db_manager)
        logger.info("MessageParsingService initialized with consensus detector")
    
    def parse_message(self, message: Dict) -> ParseResult:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            message: –¥–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            ParseResult: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        return self.parser.parse_raw_message(message)

    def parse_all_unprocessed_messages(self, limit: Optional[int] = None) -> Dict:
        try:
            unprocessed = self._get_unprocessed_messages(limit)
            
            if not unprocessed:
                logger.info("No unprocessed messages found")
                return {
                    'total_processed': 0,
                    'successful_parses': 0,
                    'failed_parses': 0,
                    'trading_messages': 0,
                    'non_trading_messages': 0,
                    'errors': []
                }
            
            stats = {
                'total_processed': 0,
                'successful_parses': 0,
                'failed_parses': 0,
                'trading_messages': 0,
                'non_trading_messages': 0,
                'errors': []
            }
            
            logger.info(f"Starting to parse {len(unprocessed)} messages...")
            
            for message in unprocessed:
                try:
                    stats['total_processed'] += 1
                    
                    result = self.parser.parse_raw_message(message)
                    
                    if result.success:
                        signal_id = self.db.save_signal(result.signal_data)
                        if signal_id:
                            stats['successful_parses'] += 1
                            stats['trading_messages'] += 1
                            self.db.mark_message_processed(message['id'], parse_success=True)

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –¥–ª—è –Ω–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
                            try:
                                signal_uuid = UUID(signal_id) if isinstance(signal_id, str) else signal_id
                                consensus_result = self.consensus_detector.check_new_signal_sync(signal_uuid)
                                if consensus_result:
                                    logger.info(f"üî• Consensus created: {consensus_result}")
                            except Exception as consensus_error:
                                logger.error(f"Failed to check consensus for signal {signal_id}: {consensus_error}")
                        else:
                            stats['failed_parses'] += 1
                            self.db.mark_message_processed(message['id'], parse_success=False)
                    else:
                        stats['failed_parses'] += 1
                        if result.error != "Not a trading message":
                            stats['errors'].append({
                                'message_id': message['id'],
                                'error': result.error
                            })
                        else:
                            stats['non_trading_messages'] += 1
                        
                        self.db.mark_message_processed(message['id'], parse_success=False)
                    
                except Exception as e:
                    logger.error(f"Error processing message {message.get('id')}: {e}")
                    stats['errors'].append({
                        'message_id': message.get('id'),
                        'error': str(e)
                    })
                    self.db.mark_message_processed(message.get('id'), parse_success=False)
            
            logger.info(f"Parsing completed: {stats['successful_parses']} successful, "
                    f"{stats['failed_parses']} failed")
            
            return stats
            
        except Exception as e:
            logger.error(f"Failed to parse messages: {e}")
            return {
                'total_processed': 0,
                'successful_parses': 0,
                'failed_parses': 0,
                'errors': [{'error': str(e)}]
            }

    def _get_unprocessed_messages(self, limit: Optional[int]) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ë–î"""
        messages = self.db.get_unparsed_messages(limit=limit or 100)
        return messages
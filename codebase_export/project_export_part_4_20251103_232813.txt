=== EXPORT PART 4/10 ===

=== –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ï–ì–û –§–ê–ô–õ–ê ===

# integrations/historical_data_loader.py
import logging
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from pathlib import Path
from core.database.database import Instrument,Candle
from utils.datetime_utils import now_utc, utc_from_days_ago, utc_from_minutes_ago, ensure_timezone_aware, days_between_utc
from .tinkoff_integration import TinkoffIntegration
from core.database import Database
from sqlalchemy import func

logger = logging.getLogger(__name__)

class HistoricalDataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Tinkoff API –≤ –±–∞–∑—É"""
    
    def __init__(self, db: Database, tinkoff_client: TinkoffIntegration):
        self.db = db
        self.tinkoff = tinkoff_client
        self.mapping_file = Path("instruments_mapping.json")
        
    async def load_instruments_mapping(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        try:
            if self.mapping_file.exists():
                with open(self.mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
                    logger.info(f"üìã Loaded {len(mapping['instruments'])} instruments from mapping")
                    return mapping
            else:
                logger.warning("‚ö†Ô∏è Instruments mapping file not found, creating from API...")
                return await self.create_instruments_mapping()
                
        except Exception as e:
            logger.error(f"‚ùå Error loading instruments mapping: {e}")
            return {"instruments": {}}
    
    async def create_instruments_mapping(self) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ API"""
        popular_instruments = await self.tinkoff.get_popular_instruments()
        
        mapping = {
            "description": "Auto-generated mapping from Tinkoff API",
            "last_updated": datetime.now().isoformat(),
            "instruments": {}
        }
        
        for instrument in popular_instruments:
            mapping["instruments"][instrument["ticker"]] = {
                "figi": instrument["figi"],
                "name": instrument["name"],
                "type": instrument["type"],
                "currency": instrument["currency"]
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥
        try:
            with open(self.mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping, f, indent=2, ensure_ascii=False)
            logger.info(f"üíæ Saved instruments mapping to {self.mapping_file}")
        except Exception as e:
            logger.error(f"‚ùå Error saving mapping: {e}")
        
        return mapping
    
    async def sync_instruments_to_database(self) -> int:
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            mapping = await self.load_instruments_mapping()
            synced_count = 0
            
            for ticker, info in mapping.get("instruments", {}).items():
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥ Database
                    figi = self.db.save_instrument(
                        figi=info["figi"],
                        ticker=ticker,
                        name=info["name"],
                        instrument_type=info.get("type", "share")
                    )
                    
                    if figi:
                        synced_count += 1
                        logger.info(f"‚úÖ Synced instrument: {ticker} ({info['name']})")
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to sync instrument: {ticker}")
                        
                except Exception as e:
                    logger.error(f"‚ùå Error syncing {ticker}: {e}")
            
            logger.info(f"üìä Synced {synced_count} instruments to database")
            return synced_count
            
        except Exception as e:
            logger.error(f"‚ùå Error syncing instruments: {e}")
            return 0

    async def load_historical_candles(
        self,
        ticker: str,
        interval: str = "5min", 
        days_back: int = 30,
        force_reload: bool = False
    ) -> Dict:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–≤–µ—á–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞
        
        Args:
            ticker: –¢–∏–∫–µ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "SBER")
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π ("1min", "5min", "hour", "day")  
            days_back: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            force_reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ (–æ—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ)
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ —á–µ—Ä–µ–∑ –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥
            instrument = self.db.get_instrument_by_ticker(ticker)
            if not instrument:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ API –∏ –¥–æ–±–∞–≤–∏—Ç—å –≤ –±–∞–∑—É
                api_instrument = await self.tinkoff.find_instrument_by_ticker(ticker)
                if not api_instrument:
                    return {
                        "success": False,
                        "error": f"Instrument {ticker} not found",
                        "loaded_candles": 0
                    }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤ –±–∞–∑—É
                self.db.save_instrument(
                    figi=api_instrument["figi"],
                    ticker=ticker,
                    name=api_instrument["name"],
                    instrument_type=api_instrument.get("type", "share")
                )
                
                instrument = {"figi": api_instrument["figi"]}
            
            figi = instrument["figi"]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥
            if not force_reload:
                existing_candles = self.db.get_candles(
                    figi=figi,
                    interval=interval,
                    limit=10
                )
                
                if existing_candles:
                    logger.info(f"üìä Found {len(existing_candles)} existing candles for {ticker}")
                    
                    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å –∫–∞–∫–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å
                    # –í—Å–µ –¥–∞—Ç—ã –∏–∑ –ë–î —É–∂–µ timezone-aware (UTC)
                    last_candle_time = max(candle['time'] for candle in existing_candles)
                    last_candle_time = ensure_timezone_aware(last_candle_time)  # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                    
                    from_time = last_candle_time + timedelta(minutes=1)
                    to_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: timezone-aware
                    
                    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ timezone-aware –¥–∞—Ç
                    if from_time >= to_time:
                        return {
                            "success": True,
                            "message": "Data is up to date",
                            "loaded_candles": 0,
                            "existing_candles": len(existing_candles)
                        }
                else:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–µ—Ä–∏–æ–¥
                    from_time = utc_from_days_ago(days_back)  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                    to_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            else:
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ - –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥
                from_time = utc_from_days_ago(days_back)  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                to_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ—á–∏ —á–µ—Ä–µ–∑ API
            logger.info(f"üìà Loading {interval} candles for {ticker} from {from_time.date()} to {to_time.date()}")
            
            candles_data = await self.tinkoff.get_candles(
                figi=figi,
                interval=interval,
                from_time=from_time,
                to_time=to_time
            )
            
            if not candles_data:
                return {
                    "success": False,
                    "error": "No candles received from API",
                    "loaded_candles": 0
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–µ—á–∏ –≤ –±–∞–∑—É —á–µ—Ä–µ–∑ –≥–æ—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥
            result = self.db.save_candles(candles_data, figi=figi, interval=interval)
            
            if result.get('saved', 0) > 0:
                logger.info(f"‚úÖ Successfully loaded {len(candles_data)} candles for {ticker}")
                return {
                    "success": True,
                    "ticker": ticker,
                    "interval": interval,
                    "loaded_candles": len(candles_data),
                    "period": f"{from_time.date()} - {to_time.date()}"
                }
            else:
                return {
                    "success": False,
                    "error": "Failed to save candles to database",
                    "loaded_candles": 0
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error loading historical candles for {ticker}: {e}")
            return {
                "success": False,
                "error": str(e),
                "loaded_candles": 0
            }

    async def bulk_load_popular_instruments(
        self,
        interval: str = "5min",
        days_back: int = 30,
        max_concurrent: int = 3
    ) -> Dict:
        """
        –ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        
        Args:
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π
            days_back: –î–Ω–µ–π –Ω–∞–∑–∞–¥
            max_concurrent: –ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫
        """
        try:
            mapping = await self.load_instruments_mapping()
            popular_tickers = list(mapping.get("demo_signals", {}).get("most_traded", []))
            
            if not popular_tickers:
                popular_tickers = ["SBER", "GAZP", "LKOH", "YNDX", "VTBR"]
            
            logger.info(f"üöÄ Starting bulk load for {len(popular_tickers)} instruments")
            
            results = {
                "completed": [],
                "failed": [],
                "total_candles": 0,
                "total_requested": len(popular_tickers),
                "start_time": now_utc().isoformat(),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            }
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è concurrent –∑–∞–ø—Ä–æ—Å–æ–≤
            semaphore = asyncio.Semaphore(max_concurrent)
            
            async def load_single_ticker(ticker):
                async with semaphore:
                    result = await self.load_historical_candles(
                        ticker=ticker,
                        interval=interval,
                        days_back=days_back
                    )
                    
                    if result["success"]:
                        results["completed"].append(result)
                        results["total_candles"] += result["loaded_candles"]
                    else:
                        results["failed"].append({
                            "ticker": ticker,
                            "error": result["error"]
                        })
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–≥—Ä—É–∑–∫–∞–º–∏
                    await asyncio.sleep(1)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
            tasks = [load_single_ticker(ticker) for ticker in popular_tickers]
            await asyncio.gather(*tasks, return_exceptions=True)
            
            results["end_time"] = now_utc().isoformat()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            results["duration_minutes"] = (
                datetime.fromisoformat(results["end_time"].replace('Z', '+00:00')) - 
                datetime.fromisoformat(results["start_time"].replace('Z', '+00:00'))
            ).total_seconds() / 60
            
            logger.info(f"üìä Bulk load completed: {len(results['completed'])}/{len(popular_tickers)} successful")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Error in bulk load: {e}")
            return {
                "error": str(e),
                "completed": [],
                "failed": [],
                "total_candles": 0,
                "end_time": now_utc().isoformat()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            }
    
    async def get_data_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            with self.db.get_session() as session:
                # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                total_instruments = session.query(Instrument).count()
                total_candles = session.query(Candle).count()
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
                instruments = session.query(Instrument).limit(10).all()
                instruments_info = []
                
                for instrument in instruments:
                    candles_count = session.query(Candle).filter(
                        Candle.figi == instrument.figi
                    ).count()
                    
                    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–≤–µ—á—É —Å timezone-aware —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º
                    latest_candle = session.query(Candle).filter(
                        Candle.figi == instrument.figi
                    ).order_by(Candle.time.desc()).first()
                    
                    latest_time = None
                    if latest_candle:
                        latest_time = ensure_timezone_aware(latest_candle.time).isoformat()
                    
                    instruments_info.append({
                        "ticker": instrument.ticker,
                        "figi": instrument.figi,
                        "name": instrument.name,
                        "candles_count": candles_count,
                        "latest_candle": latest_time
                    })
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–≤–µ—á–∞–º
                candles_info = []
                candles_by_figi = session.query(
                    Candle.figi, 
                    func.count(Candle.id).label('count')
                ).group_by(Candle.figi).limit(10).all()
                
                for figi, count in candles_by_figi:
                    instrument = session.query(Instrument).filter(
                        Instrument.figi == figi
                    ).first()
                    
                    candles_info.append({
                        "figi": figi,
                        "ticker": instrument.ticker if instrument else "Unknown",
                        "candles_count": count
                    })
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
                intervals = session.query(Candle.interval).distinct().all()
                available_intervals = [interval[0] for interval in intervals]
                
                return {
                    "total_instruments": total_instruments,
                    "total_candles": total_candles,
                    "sample_instruments": instruments_info,
                    "candles_by_instrument": candles_info,
                    "available_intervals": available_intervals,
                    "status_timestamp": now_utc().isoformat(),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                    "status": "operational"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error getting data status: {e}")
            return {
                "error": str(e),
                "status": "error",
                "status_timestamp": now_utc().isoformat()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            }
    
    def _get_instruments_detailed_stats(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º"""
        instruments_info = []
        
        try:
            with self.db.session() as session:
                from core.database import Instrument, Candle
                from sqlalchemy import func
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
                instruments_stats = session.query(
                    Instrument.ticker,
                    Instrument.name,
                    func.count(Candle.id).label('candles_count'),
                    func.max(Candle.time).label('last_candle'),
                    func.min(Candle.time).label('first_candle')
                ).outerjoin(
                    Candle, Instrument.figi == Candle.instrument_id
                ).group_by(
                    Instrument.ticker, Instrument.name
                ).all()
                
                for stat in instruments_stats:
                    instruments_info.append({
                        "ticker": stat.ticker,
                        "name": stat.name,
                        "candles_count": stat.candles_count,
                        "last_candle": stat.last_candle.isoformat() if stat.last_candle else None,
                        "first_candle": stat.first_candle.isoformat() if stat.first_candle else None,
                        "has_data": stat.candles_count > 0
                    })
        except Exception as e:
            logger.error(f"‚ùå Error getting instruments stats: {e}")
        
        return instruments_info
    
    async def cleanup_old_data(self, days_to_keep: int = 90) -> Dict:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            with self.db.session() as session:
                from core.database import Candle
                
                # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ
                old_records = session.query(Candle).filter(
                    Candle.time < cutoff_date
                ).count()
                
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
                deleted = session.query(Candle).filter(
                    Candle.time < cutoff_date
                ).delete()
                
                logger.info(f"üóëÔ∏è Cleaned up {deleted} old candle records (older than {cutoff_date.date()})")
                
                return {
                    "success": True,
                    "deleted_records": deleted,
                    "cutoff_date": cutoff_date.isoformat(),
                    "days_kept": days_to_keep
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error cleaning up old data: {e}")
            return {
                "success": False,
                "error": str(e)
            }
        
    def _deduplicate_candles_data(self, candles_data: List[Dict], figi: str, interval: str) -> List[Dict]:
        """
        –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
        
        Args:
            candles_data: –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π –æ—Ç Tinkoff API
            figi: FIGI –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            interval: –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π
            
        Returns:
            List[Dict]: –æ—á–∏—â–µ–Ω–Ω—ã–µ –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã–µ
        """
        if not candles_data:
            return candles_data
        
        seen_times = set()
        deduplicated = []
        duplicates_count = 0
        
        for candle in candles_data:
            candle_time = candle['time']
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
            time_key = (figi, interval, candle_time)
            
            if time_key not in seen_times:
                seen_times.add(time_key)
                deduplicated.append(candle)
            else:
                duplicates_count += 1
                logger.warning(f"‚ö†Ô∏è Removing duplicate candle for {figi} at {candle_time}")
        
        if duplicates_count > 0:
            logger.info(f"üßπ Removed {duplicates_count} duplicate candles from {len(candles_data)} total")
        
        return deduplicated

    # –î–æ–±–∞–≤–∏—Ç—å –≤ integrations/tinkoff_integration.py

    def _validate_candles_data(self, candles: List[Dict]) -> List[Dict]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –æ—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π –æ—Ç API
        
        Args:
            candles: —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç Tinkoff API
            
        Returns:
            List[Dict]: –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        valid_candles = []
        
        for i, candle in enumerate(candles):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                required_fields = ['time', 'open', 'high', 'low', 'close']
                if not all(field in candle for field in required_fields):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: missing required fields")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å —Ü–µ–Ω
                open_price = float(candle['open'])
                high_price = float(candle['high'])
                low_price = float(candle['low'])
                close_price = float(candle['close'])
                
                if not (low_price <= open_price <= high_price and 
                    low_price <= close_price <= high_price):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: invalid OHLC values")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ü–µ–Ω—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                if any(price <= 0 for price in [open_price, high_price, low_price, close_price]):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: negative or zero prices")
                    continue
                
                valid_candles.append(candle)
                
            except (ValueError, TypeError) as e:
                logger.warning(f"‚ö†Ô∏è Skipping candle {i}: validation error {e}")
                continue
        
        logger.info(f"‚úÖ Validated {len(valid_candles)}/{len(candles)} candles")
        return valid_candles

================================================================================
File: tbot/integrations/telegram_channels_config.py
================================================================================
import os

def get_channels_from_env():
    """–ß–∏—Ç–∞–µ–º –∫–∞–Ω–∞–ª—ã –∏–∑ .env"""
    channels = []
    
    target_channel = os.getenv("target_channel_id")
    if target_channel:
        channels.append({
            "id": int(target_channel),
            "name": "Main Trading Channel",
            "enabled": True
        })
    
    test_channel = os.getenv("test_channel_id")
    if test_channel:
        channels.append({
            "id": int(test_channel),
            "name": "Test Channel",
            "enabled": False
        })
    
    return channels

CHANNELS = get_channels_from_env()

SCRAPER_CONFIG = {
    "check_interval_seconds": 60,
    "initial_history_limit": 100,
}

================================================================================
File: tbot/integrations/telegram_scraper.py
================================================================================
import logging
from datetime import datetime
from typing import List, Dict, Optional
from telethon import TelegramClient
from telethon.tl.types import Channel, Message
import asyncio

logger = logging.getLogger(__name__)

class TelegramScraper:
    """
    –°–±–æ—Ä—â–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤
    """
    
    def __init__(self, api_id: int, api_hash: str, db_manager, session_name: str = "trader_session"):
        self.api_id = api_id
        self.api_hash = api_hash
        self.db = db_manager
        self.session_name = session_name
        self.client = None
        self.is_running = False
        self.channels = {}
        
    async def initialize(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Telethon
        
        –ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ:
        1. –ü–æ–ø—Ä–æ—Å–∏—Ç –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞
        2. –ü–æ–ø—Ä–æ—Å–∏—Ç –∫–æ–¥ –∏–∑ Telegram —Å–æ–æ–±—â–µ–Ω–∏—è
        3. –ü–æ–ø—Ä–æ—Å–∏—Ç 2FA –ø–∞—Ä–æ–ª—å (–æ–±–ª–∞—á–Ω—ã–π –ø–∞—Ä–æ–ª—å)
        4. –°–æ—Ö—Ä–∞–Ω–∏—Ç —Å–µ—Å—Å–∏—é –≤ —Ñ–∞–π–ª
        
        –ü—Ä–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—É—Å–∫–∞—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é —Å–µ—Å—Å–∏—é
        """
        try:
            self.client = TelegramClient(self.session_name, self.api_id, self.api_hash)
            await self.client.start()
            logger.info("‚úÖ Telegram client initialized")
            return True
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Telegram client: {e}")
            return False
    
    async def add_channel(self, channel_id: int, name: str, enabled: bool = True):
        """
        –î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        
        Args:
            channel_id: ID –∫–∞–Ω–∞–ª–∞ –≤ Telegram
            name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –ª–æ–≥–æ–≤
            enabled: –ê–∫—Ç–∏–≤–µ–Ω –ª–∏ –∫–∞–Ω–∞–ª
        """
        try:
            entity = None
            
            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ –¥–∏–∞–ª–æ–≥–∞—Ö (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±)
            async for dialog in self.client.iter_dialogs():
                if dialog.entity.id == channel_id:
                    entity = dialog.entity
                    actual_name = dialog.title
                    logger.info(f"‚úÖ Found channel in dialogs: {actual_name}")
                    break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö, –ø—Ä–æ–±—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
            if not entity:
                logger.warning(f"Channel {channel_id} not in dialogs, trying direct access...")
                entity = await self.client.get_entity(channel_id)
                actual_name = name
            
            self.channels[channel_id] = {
                'id': channel_id,
                'name': actual_name if entity else name,
                'entity': entity,
                'enabled': enabled,
                'last_message_id': None,
                'total_collected': 0
            }
            
            logger.info(f"‚úÖ Channel added: {actual_name if entity else name} (ID: {channel_id})")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to add channel {channel_id}: {e}")
            return False
    
    async def fetch_history(self, channel_id: int, limit: int = 100) -> int:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞
        
        Args:
            channel_id: ID –∫–∞–Ω–∞–ª–∞
            limit: –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π
            
        Returns:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        if channel_id not in self.channels:
            logger.error(f"‚ùå Channel {channel_id} not configured")
            return 0
        
        channel = self.channels[channel_id]
        if not channel['enabled']:
            logger.warning(f"‚ö†Ô∏è Channel {channel['name']} is disabled")
            return 0
        
        try:
            entity = channel['entity']
            collected = 0
            
            logger.info(f"üì• Fetching history from {channel['name']} (limit: {limit})...")
            
            async for message in self.client.iter_messages(entity, limit=limit):
                if await self._save_message(channel_id, message):
                    collected += 1
                    
                    if channel['last_message_id'] is None or message.id > channel['last_message_id']:
                        channel['last_message_id'] = message.id
            
            channel['total_collected'] += collected
            logger.info(f"‚úÖ Collected {collected} messages from {channel['name']}")
            return collected
            
        except Exception as e:
            logger.error(f"‚ùå Error fetching history from {channel_id}: {e}")
            return 0
    
    async def fetch_new_messages(self, channel_id: int) -> int:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–ø–æ—Å–ª–µ last_message_id)
        
        Args:
            channel_id: ID –∫–∞–Ω–∞–ª–∞
            
        Returns:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        if channel_id not in self.channels:
            return 0
        
        channel = self.channels[channel_id]
        if not channel['enabled']:
            return 0
        
        try:
            entity = channel['entity']
            last_id = channel['last_message_id'] or 0
            collected = 0
            
            async for message in self.client.iter_messages(entity, min_id=last_id, limit=100):
                if await self._save_message(channel_id, message):
                    collected += 1
                    
                    if message.id > last_id:
                        channel['last_message_id'] = message.id
            
            if collected > 0:
                channel['total_collected'] += collected
                logger.info(f"‚úÖ Collected {collected} new messages from {channel['name']}")
            
            return collected
            
        except Exception as e:
            logger.error(f"‚ùå Error fetching new messages from {channel_id}: {e}")
            return 0
    
    async def _save_message(self, channel_id: int, message: Message) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ë–î (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
        
        Args:
            channel_id: ID –∫–∞–Ω–∞–ª–∞
            message: –û–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telethon
            
        Returns:
            bool: True –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ, False –µ—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            if not message.text:
                return False
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            message_id = self.db.save_message(
                channel_id=channel_id,
                message_id=message.id,
                timestamp=message.date,
                text=message.text,
                is_processed=False
            )
            
            if message_id:
                return True
            return False
            
        except Exception as e:
            if "duplicate key" in str(e).lower() or "unique constraint" in str(e).lower():
                return False
            
            logger.error(f"‚ùå Error saving message {message.id}: {e}")
            return False
    
    async def start_monitoring(self, interval_seconds: int = 60):
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞–Ω–∞–ª–æ–≤ –≤ —Ñ–æ–Ω–µ
        
        Args:
            interval_seconds: –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        self.is_running = True
        logger.info(f"üîÑ Started monitoring with interval {interval_seconds}s")
        
        while self.is_running:
            try:
                for channel_id in self.channels:
                    if self.channels[channel_id]['enabled']:
                        await self.fetch_new_messages(channel_id)
                
                await asyncio.sleep(interval_seconds)
                
            except Exception as e:
                logger.error(f"‚ùå Error in monitoring loop: {e}")
                await asyncio.sleep(interval_seconds)
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        self.is_running = False
        logger.info("‚è∏Ô∏è Monitoring stopped")
    
    def get_status(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–±–æ—Ä—â–∏–∫–∞"""
        channels_status = []
        
        for ch_id, ch_data in self.channels.items():
            channels_status.append({
                'id': ch_id,
                'name': ch_data['name'],
                'enabled': ch_data['enabled'],
                'last_message_id': ch_data['last_message_id'],
                'total_collected': ch_data['total_collected']
            })
        
        return {
            'is_running': self.is_running,
            'client_connected': self.client is not None and self.client.is_connected(),
            'channels': channels_status
        }
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ"""
        self.stop_monitoring()
        if self.client:
            await self.client.disconnect()
            logger.info("üëã Telegram client disconnected")

================================================================================
File: tbot/integrations/tinkoff_integration.py
================================================================================
# integrations/tinkoff_integration.py
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple
import pytz
import os

logger = logging.getLogger(__name__)

class TinkoffIntegration:
    """–ü–û–õ–ù–ê–Ø –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Tinkoff API —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target + –≤—Å–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã"""
    
    def __init__(self, token: str, sandbox: bool = True):
        self.token = token
        self.sandbox = sandbox
        self.client = None
        self.instruments_cache = {}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
        try:
            global AsyncClient, CandleInterval, InstrumentIdType
            from tinkoff.invest import AsyncClient, CandleInterval, InstrumentIdType
            
            # üî• –ö–õ–Æ–ß–ï–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è target
            from tinkoff.invest.constants import INVEST_GRPC_API, INVEST_GRPC_API_SANDBOX
            self.target = INVEST_GRPC_API_SANDBOX if sandbox else INVEST_GRPC_API
            
            logger.info(f"üéØ Target set to: {'SANDBOX' if sandbox else 'PRODUCTION'}")
            
        except ImportError:
            logger.error("‚ùå Tinkoff Invest library not found. Install: pip install tinkoff-invest")
            raise ImportError("tinkoff-invest library required")
        
    async def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target"""
        try:
            if not self.token or self.token == "your_tinkoff_token_here":
                logger.error("‚ùå Tinkoff token not configured")
                return False
                
            logger.info(f"üîó Initializing Tinkoff API (sandbox={self.sandbox})")
            
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º target –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–æ–Ω—Ç—É—Ä–∞
            async with AsyncClient(self.token, target=self.target) as client:
                # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç - –ø–æ–ª—É—á–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã
                accounts = await client.users.get_accounts()
                logger.info(f"‚úÖ Tinkoff client initialized successfully")
                logger.info(f"üìä Found {len(accounts.accounts)} accounts")
                logger.info(f"üéØ Using {'SANDBOX' if self.sandbox else 'PRODUCTION'} environment")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø–æ–∏—Å–∫ –ø—Ä–æ—Å—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
                try:
                    test_response = await client.instruments.shares()
                    logger.info(f"üîç Found {len(test_response.instruments)} shares available")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not fetch shares list: {e}")
                
                return True
                
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Tinkoff client: {e}")
            logger.error(f"üîß Debug info: token length={len(self.token)}, sandbox={self.sandbox}, target={getattr(self, 'target', 'NOT_SET')}")
            return False
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        logger.info("üîÑ Tinkoff client closed")
    
    async def find_instrument_by_ticker(self, ticker: str) -> Optional[Dict]:
        """–ü–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ —Ç–∏–∫–µ—Ä—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target"""
        async with AsyncClient(self.token, target=self.target) as client:
            try:
                logger.info(f"üîç Searching for instrument: {ticker}")
                
                ticker_upper = ticker.upper()
                found_instruments = []
                
                instrument_types = [
                    ("shares", client.instruments.shares),
                    ("etfs", client.instruments.etfs),
                    ("bonds", client.instruments.bonds),
                    ("futures", client.instruments.futures),
                    ("currencies", client.instruments.currencies)
                ]
                
                for type_name, instrument_method in instrument_types:
                    try:
                        response = await instrument_method()
                        
                        for instrument in response.instruments:
                            instrument_ticker_upper = instrument.ticker.upper()
                            
                            if instrument_ticker_upper == ticker_upper:
                                result = {
                                    "figi": instrument.figi,
                                    "ticker": instrument.ticker,
                                    "name": instrument.name,
                                    "type": type_name,
                                    "currency": instrument.currency,
                                    "lot": instrument.lot,
                                    "trading_status": str(instrument.trading_status) if hasattr(instrument, 'trading_status') else 'unknown'
                                }
                                logger.info(f"‚úÖ Found exact match {ticker}: {result['name']} ({result['figi']})")
                                return result
                            
                            elif instrument_ticker_upper.startswith(ticker_upper):
                                found_instruments.append({
                                    "figi": instrument.figi,
                                    "ticker": instrument.ticker,
                                    "name": instrument.name,
                                    "type": type_name,
                                    "currency": instrument.currency,
                                    "lot": instrument.lot,
                                    "trading_status": str(instrument.trading_status) if hasattr(instrument, 'trading_status') else 'unknown'
                                })
                                
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Error searching in {type_name}: {e}")
                        continue
                
                if found_instruments:
                    logger.info(f"üîé Found {len(found_instruments)} partial matches for '{ticker}':")
                    for idx, inst in enumerate(found_instruments[:5]):
                        logger.info(f"  {idx+1}. {inst['ticker']} - {inst['name']} ({inst['type']})")
                    
                    logger.info(f"‚úÖ Returning first match: {found_instruments[0]['ticker']}")
                    return found_instruments[0]
                
                logger.warning(f"‚ùå Instrument {ticker} not found")
                return None
                
            except Exception as e:
                logger.error(f"‚ùå Error searching for {ticker}: {e}")
                return None

    async def get_current_price(self, ticker: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
            instrument = await self.find_instrument_by_ticker(ticker)
            if not instrument:
                return None
            
            async with AsyncClient(self.token, target=self.target) as client:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ–Ω—É
                response = await client.market_data.get_last_prices(
                    figi=[instrument['figi']]
                )
                
                if response.last_prices:
                    last_price = response.last_prices[0]
                    price_value = float(last_price.price.units) + float(last_price.price.nano) / 1e9
                    
                    return {
                        "ticker": ticker,
                        "figi": instrument['figi'],
                        "price": price_value,
                        "currency": instrument['currency'],
                        "timestamp": datetime.now().isoformat(),
                        "source": f"tinkoff_api_{'sandbox' if self.sandbox else 'production'}"
                    }
                
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error getting price for {ticker}: {e}")
            return None

    async def get_candles(self, figi: str, interval: str, from_time: datetime, to_time: Optional[datetime] = None) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π"""
        try:
            if to_time is None:
                to_time = datetime.now(pytz.UTC)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª
            interval_map = {
                "1min": CandleInterval.CANDLE_INTERVAL_1_MIN,
                "5min": CandleInterval.CANDLE_INTERVAL_5_MIN,
                "hour": CandleInterval.CANDLE_INTERVAL_HOUR,
                "day": CandleInterval.CANDLE_INTERVAL_DAY
            }
            
            if interval not in interval_map:
                logger.error(f"‚ùå Unsupported interval: {interval}")
                return []
            
            candles = []
            async with AsyncClient(self.token, target=self.target) as client:
                async for candle in client.get_all_candles(
                    figi=figi,
                    from_=from_time,
                    to=to_time,
                    interval=interval_map[interval]
                ):
                    candles.append({
                        "time": candle.time,
                        "open": float(candle.open.units) + float(candle.open.nano) / 1e9,
                        "high": float(candle.high.units) + float(candle.high.nano) / 1e9,
                        "low": float(candle.low.units) + float(candle.low.nano) / 1e9,
                        "close": float(candle.close.units) + float(candle.close.nano) / 1e9,
                        "volume": candle.volume
                    })
            
            logger.info(f"üìä Received {len(candles)} raw candles from Tinkoff API")
            
            # üÜï –í–ê–õ–ò–î–ò–†–£–ï–ú –ò –û–ß–ò–©–ê–ï–ú –î–ê–ù–ù–´–ï
            validated_candles = self._validate_candles_data(candles)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            validated_candles.sort(key=lambda x: x['time'])
            
            logger.info(f"‚úÖ Returning {len(validated_candles)} validated candles")
            return validated_candles
            
        except Exception as e:
            logger.error(f"‚ùå Error getting candles for {figi}: {e}")
            return []


    async def test_connection(self) -> Dict:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target"""
        try:
            async with AsyncClient(self.token, target=self.target) as client:
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–∫–∫–∞—É–Ω—Ç–µ
                accounts = await client.users.get_accounts()
                
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
                test_instrument = await self.find_instrument_by_ticker("SBER")
                
                return {
                    "success": True,
                    "sandbox": self.sandbox,
                    "target": "SANDBOX" if self.sandbox else "PRODUCTION",
                    "accounts_count": len(accounts.accounts),
                    "test_instrument": test_instrument is not None,
                    "test_ticker": "SBER",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "sandbox": self.sandbox,
                "target": "SANDBOX" if self.sandbox else "PRODUCTION",
                "timestamp": datetime.now().isoformat()
            }

    def _validate_candles_data(self, candles: List[Dict]) -> List[Dict]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –æ—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π –æ—Ç API
        
        Args:
            candles: —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç Tinkoff API
            
        Returns:
            List[Dict]: –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        valid_candles = []
        
        for i, candle in enumerate(candles):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                required_fields = ['time', 'open', 'high', 'low', 'close']
                if not all(field in candle for field in required_fields):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: missing required fields")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å —Ü–µ–Ω
                open_price = float(candle['open'])
                high_price = float(candle['high'])
                low_price = float(candle['low'])
                close_price = float(candle['close'])
                
                if not (low_price <= open_price <= high_price and 
                    low_price <= close_price <= high_price):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: invalid OHLC values")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ü–µ–Ω—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                if any(price <= 0 for price in [open_price, high_price, low_price, close_price]):
                    logger.warning(f"‚ö†Ô∏è Skipping candle {i}: negative or zero prices")
                    continue
                
                valid_candles.append(candle)
                
            except (ValueError, TypeError) as e:
                logger.warning(f"‚ö†Ô∏è Skipping candle {i}: validation error {e}")
                continue
        
        logger.info(f"‚úÖ Validated {len(valid_candles)}/{len(candles)} candles")
        return valid_candles

    async def get_popular_instruments(self, limit: int = 50) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target"""
        try:
            async with AsyncClient(self.token, target=self.target) as client:
                shares_response = await client.instruments.shares()
                
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ limit –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
                instruments = []
                for instrument in shares_response.instruments[:limit]:
                    instruments.append({
                        "figi": instrument.figi,
                        "ticker": instrument.ticker,
                        "name": instrument.name,
                        "currency": instrument.currency,
                        "lot": instrument.lot,
                        "type": "share"
                    })
                
                logger.info(f"üìä Loaded {len(instruments)} popular instruments")
                return instruments
                
        except Exception as e:
            logger.error(f"‚ùå Error loading popular instruments: {e}")
            return []

    async def bulk_load_instruments(self, tickers: List[str]) -> Dict:
        """üîÑ –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ô –ú–ï–¢–û–î: –ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
        results = {
            "loaded": [],
            "failed": [],
            "total_requested": len(tickers),
            "total_loaded": 0
        }
        
        for i, ticker in enumerate(tickers):
            try:
                logger.info(f"üîç Loading {i+1}/{len(tickers)}: {ticker}")
                instrument = await self.find_instrument_by_ticker(ticker)
                
                if instrument:
                    results["loaded"].append(instrument)
                    results["total_loaded"] += 1
                else:
                    results["failed"].append({"ticker": ticker, "error": "Not found"})
                    
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                await asyncio.sleep(0.1)
                
            except Exception as e:
                results["failed"].append({"ticker": ticker, "error": str(e)})
                logger.error(f"‚ùå Error loading {ticker}: {e}")
        
        logger.info(f"üìä Bulk load completed: {results['total_loaded']}/{results['total_requested']}")
        return results

    async def get_account_info(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–∫–∫–∞—É–Ω—Ç–µ"""
        try:
            async with AsyncClient(self.token, target=self.target) as client:
                accounts = await client.users.get_accounts()
                
                account_info = []
                for account in accounts.accounts:
                    account_info.append({
                        "id": account.id,
                        "name": account.name,
                        "type": str(account.type),
                        "status": str(account.status),
                        "access_level": str(account.access_level)
                    })
                
                return {
                    "success": True,
                    "accounts": account_info,
                    "total_accounts": len(account_info)
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error getting account info: {e}")
            return {
                "success": False,
                "error": str(e),
                "accounts": []
            }

    async def get_instrument_by_figi(self, figi: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ FIGI"""
        try:
            async with AsyncClient(self.token, target=self.target) as client:
                response = await client.instruments.get_instrument_by(
                    id_type=InstrumentIdType.INSTRUMENT_ID_TYPE_FIGI,
                    id=figi
                )
                
                if response.instrument:
                    instrument = response.instrument
                    return {
                        "figi": instrument.figi,
                        "ticker": instrument.ticker,
                        "name": instrument.name,
                        "currency": instrument.currency,
                        "lot": instrument.lot,
                        "type": "unknown"  # –ù—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –æ—Ç–¥–µ–ª—å–Ω–æ
                    }
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error getting instrument by FIGI {figi}: {e}")
            return None

    async def search_instruments(self, query: str, limit: int = 20) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        try:
            # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ - –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–∞–∫ —Ç–∏–∫–µ—Ä
            if len(query) <= 6 and query.isupper():
                instrument = await self.find_instrument_by_ticker(query)
                if instrument:
                    return [instrument]
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
            results = []
            async with AsyncClient(self.token, target=self.target) as client:
                instrument_types = [
                    ("shares", client.instruments.shares),
                    ("etfs", client.instruments.etfs),
                    ("bonds", client.instruments.bonds),
                ]
                
                for type_name, instrument_method in instrument_types:
                    try:
                        response = await instrument_method()
                        for instrument in response.instruments:
                            if (query.upper() in instrument.ticker.upper() or 
                                query.upper() in instrument.name.upper()):
                                results.append({
                                    "figi": instrument.figi,
                                    "ticker": instrument.ticker,
                                    "name": instrument.name,
                                    "type": type_name,
                                    "currency": instrument.currency,
                                    "lot": instrument.lot
                                })
                                
                                if len(results) >= limit:
                                    break
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Error searching in {type_name}: {e}")
                        continue
                        
                    if len(results) >= limit:
                        break
            
            logger.info(f"üîç Found {len(results)} instruments for query '{query}'")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Error searching instruments: {e}")

            return []

# –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
async def create_tinkoff_client() -> TinkoffIntegration:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Tinkoff –∫–ª–∏–µ–Ω—Ç–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target"""
    token = os.getenv("TINKOFF_TOKEN")
    sandbox = os.getenv("TINKOFF_SANDBOX", "false").lower() == "true"
    
    if not token:
        raise ValueError("TINKOFF_TOKEN environment variable not set")
    
    client = TinkoffIntegration(token, sandbox)
    success = await client.initialize()
    
    if not success:
        raise Exception("Failed to initialize Tinkoff client")
    
    return client


# üîÑ –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞
async def sync_instruments_from_tinkoff(tinkoff_client, instrument_type="shares"):
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
    if instrument_type == "shares":
        instruments = await tinkoff_client.get_popular_instruments()
        return len(instruments)
    return 0

async def get_missing_candles_for_signals(tinkoff_client):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Å–≤–µ—á–µ–π –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –ø–æ–∑–∂–µ –ø—Ä–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å SignalMatcher
    logger.info("üïØÔ∏è Getting missing candles for signals...")
    return 0



================================================================================
File: tbot/analysis/consensus_detector.py
================================================================================
"""
–°–µ—Ä–≤–∏—Å –¥–µ—Ç–µ–∫—Ü–∏–∏ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ —Ç—Ä–µ–π–¥–µ—Ä–æ–≤
Event-driven –ø–æ–¥—Ö–æ–¥: –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –ø—Ä–∏ –∫–∞–∂–¥–æ–º –Ω–æ–≤–æ–º —Å–∏–≥–Ω–∞–ª–µ
MVP –≤–µ—Ä—Å–∏—è —Å –∑–∞–≥–æ—Ç–æ–≤–∫–æ–π –ø–æ–¥ V1
"""

import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from uuid import UUID

from sqlalchemy import and_, func
from core.database.database import Database
from core.database.models import ParsedSignal, ConsensusEvent, ConsensusSignal
from utils.datetime_utils import now_utc, ensure_timezone_aware

logger = logging.getLogger(__name__)


class ConsensusDetector:
    """
    –î–µ—Ç–µ–∫—Ç–æ—Ä –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ —Ç—Ä–µ–π–¥–µ—Ä–æ–≤
    MVP –≤–µ—Ä—Å–∏—è —Å –∑–∞–≥–æ—Ç–æ–≤–∫–æ–π –ø–æ–¥ V1
    """
    
    def __init__(self, db: Database):
        self.db = db
        
        self.default_window_minutes = 30
        self.default_min_traders = 3
        self.strict_consensus = True
        
        logger.info("‚úÖ ConsensusDetector initialized (MVP mode)")
    
    async def check_new_signal(self, signal_id: UUID) -> Optional[Dict]:
        """
        Event-driven –ø—Ä–æ–≤–µ—Ä–∫–∞: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–∫–Ω–æ –≤–æ–∫—Ä—É–≥ –Ω–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
        
        Args:
            signal_id: UUID –Ω–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
            
        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–µ –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω, –∏–Ω–∞—á–µ None
        """
        try:
            with self.db.session() as session:
                signal = session.query(ParsedSignal).filter(
                    ParsedSignal.id == signal_id
                ).first()
                
                if not signal:
                    logger.warning(f"Signal {signal_id} not found")
                    return None
                
                if signal.signal_type != 'entry':
                    logger.debug(f"Signal {signal_id} is not entry type, skipping")
                    return None
                
                existing = session.query(ConsensusSignal).filter(
                    ConsensusSignal.signal_id == signal_id
                ).first()
                
                if existing:
                    logger.debug(f"Signal {signal_id} already in consensus")
                    return None
                
                logger.info(f"üîç Checking consensus for: {signal.ticker} {signal.direction} by {signal.author}")
                
                consensus_data = self._find_consensus_window(session, signal)
                
                if consensus_data:
                    consensus_event = self._create_consensus_event(
                        session, 
                        signal, 
                        consensus_data
                    )
                    
                    logger.info(
                        f"üî• CONSENSUS DETECTED: {consensus_event.ticker} {consensus_event.direction} "
                        f"- {consensus_event.traders_count} traders in {consensus_event.window_minutes}min"
                    )
                    
                    return {
                        'consensus_id': str(consensus_event.id),
                        'ticker': consensus_event.ticker,
                        'direction': consensus_event.direction,
                        'traders_count': consensus_event.traders_count,
                        'window_minutes': consensus_event.window_minutes,
                        'strength': consensus_event.consensus_strength
                    }
                
                return None
                
        except Exception as e:
            logger.error(f"Error checking signal {signal_id}: {e}", exc_info=True)
            return None
    

=== –ö–û–î –û–ë–†–´–í–ê–ï–¢–°–Ø. –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –í –°–õ–ï–î–£–Æ–©–ï–ú –§–ê–ô–õ–ï ===


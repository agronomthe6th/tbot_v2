=== EXPORT PART 5/10 ===

=== –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ï–ì–û –§–ê–ô–õ–ê ===

    def _find_consensus_window(self, session, signal: ParsedSignal) -> Optional[Dict]:
        """–ò—â–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –≤ –æ–∫–Ω–µ –≤–æ–∫—Ä—É–≥ —Å–∏–≥–Ω–∞–ª–∞"""
        ticker = signal.ticker
        direction = signal.direction
        signal_time = signal.timestamp
        
        window_start = signal_time - timedelta(minutes=self.default_window_minutes / 2)
        window_end = signal_time + timedelta(minutes=self.default_window_minutes / 2)
        
        window_signals = session.query(ParsedSignal).filter(
            and_(
                ParsedSignal.ticker == ticker,
                ParsedSignal.signal_type == 'entry',
                ParsedSignal.timestamp >= window_start,
                ParsedSignal.timestamp <= window_end,
                ParsedSignal.direction.isnot(None)
            )
        ).all()
        
        if len(window_signals) < self.default_min_traders:
            logger.debug(
                f"Not enough signals: {len(window_signals)} < {self.default_min_traders}"
            )
            return None
        
        direction_groups = self._group_by_direction(window_signals)
        
        if self.strict_consensus:
            if len(direction_groups) > 1:
                logger.debug(f"Mixed directions: {list(direction_groups.keys())}")
                return None
            
            consensus_direction = list(direction_groups.keys())[0]
            consensus_signals = direction_groups[consensus_direction]
        else:
            consensus_direction = max(direction_groups, key=lambda d: len(direction_groups[d]))
            consensus_signals = direction_groups[consensus_direction]
        
        unique_authors = set(s.author for s in consensus_signals if s.author)
        
        if len(unique_authors) < self.default_min_traders:
            logger.debug(
                f"Not enough unique authors: {len(unique_authors)} < {self.default_min_traders}"
            )
            return None
        
        return {
            'signals': consensus_signals,
            'direction': consensus_direction,
            'unique_authors': unique_authors,
            'window_start': window_start,
            'window_end': window_end
        }
    
    def _group_by_direction(self, signals: List[ParsedSignal]) -> Dict[str, List[ParsedSignal]]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é"""
        groups = {}
        for signal in signals:
            direction = signal.direction
            if direction not in groups:
                groups[direction] = []
            groups[direction].append(signal)
        return groups
    
    def _create_consensus_event(self, session, trigger_signal: ParsedSignal, consensus_data: Dict) -> ConsensusEvent:
        """–°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞"""
        signals = consensus_data['signals']
        
        signals_sorted = sorted(signals, key=lambda s: s.timestamp)
        first_signal = signals_sorted[0]
        last_signal = signals_sorted[-1]
        
        prices = [s.target_price for s in signals if s.target_price]
        
        avg_price = sum(prices) / len(prices) if prices else None
        min_price = min(prices) if prices else None
        max_price = max(prices) if prices else None
        
        price_spread = None
        if avg_price and min_price and max_price and avg_price > 0:
            price_spread = ((max_price - min_price) / avg_price) * 100
        
        strength = self._calculate_strength(consensus_data, price_spread)
        
        consensus_event = ConsensusEvent(
            ticker=trigger_signal.ticker,
            direction=consensus_data['direction'],
            traders_count=len(consensus_data['unique_authors']),
            window_minutes=self.default_window_minutes,
            first_signal_at=first_signal.timestamp,
            last_signal_at=last_signal.timestamp,
            avg_entry_price=avg_price,
            min_entry_price=min_price,
            max_entry_price=max_price,
            price_spread_pct=price_spread,
            consensus_strength=strength,
            status='active',
            metadata={
                'authors': list(consensus_data['unique_authors']),
                'trigger_signal_id': str(trigger_signal.id),
                'total_signals': len(signals)
            }
        )
        
        session.add(consensus_event)
        session.flush()
        
        for signal in signals:
            consensus_signal = ConsensusSignal(
                consensus_id=consensus_event.id,
                signal_id=signal.id,
                is_initiator=(signal.id == trigger_signal.id)
            )
            session.add(consensus_signal)
        
        session.commit()
        
        return consensus_event
    
    def _calculate_strength(self, consensus_data: Dict, price_spread: Optional[float]) -> int:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∏–ª—É –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ (0-100)
        
        –§–∞–∫—Ç–æ—Ä—ã:
        - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ (–±–æ–ª—å—à–µ = –ª—É—á—à–µ)
        - –†–∞–∑–±—Ä–æ—Å —Ü–µ–Ω (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
        - –í—Ä–µ–º–µ–Ω–Ω–∞—è –∫—É—á–Ω–æ—Å—Ç—å (–≤—Å–µ —Å–∏–≥–Ω–∞–ª—ã –±–ª–∏–∑–∫–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ = –ª—É—á—à–µ)
        """
        strength = 50
        
        traders_count = len(consensus_data['unique_authors'])
        if traders_count >= 5:
            strength += 20
        elif traders_count >= 4:
            strength += 10
        
        if price_spread is not None:
            if price_spread < 1:
                strength += 15
            elif price_spread < 2:
                strength += 5
            elif price_spread > 5:
                strength -= 10
        
        signals = consensus_data['signals']
        if len(signals) > 1:
            time_span = (max(s.timestamp for s in signals) - min(s.timestamp for s in signals)).total_seconds() / 60
            if time_span < 10:
                strength += 15
            elif time_span < 20:
                strength += 5
        
        return max(0, min(100, strength))
    
    def get_consensus_stats(self, ticker: Optional[str] = None, days_back: int = 30) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞–º"""
        try:
            with self.db.session() as session:
                query = session.query(ConsensusEvent)
                
                if ticker:
                    query = query.filter(ConsensusEvent.ticker == ticker)
                
                if days_back:
                    cutoff_date = now_utc() - timedelta(days=days_back)
                    query = query.filter(ConsensusEvent.detected_at >= cutoff_date)
                
                total = query.count()
                
                by_status = {}
                for status in ['active', 'closed', 'expired']:
                    count = query.filter(ConsensusEvent.status == status).count()
                    by_status[status] = count
                
                avg_strength = session.query(func.avg(ConsensusEvent.consensus_strength)).filter(
                    query.whereclause
                ).scalar()
                
                return {
                    'total': total,
                    'by_status': by_status,
                    'avg_strength': float(avg_strength) if avg_strength else 0,
                    'period_days': days_back,
                    'ticker': ticker
                }
                
        except Exception as e:
            logger.error(f"Error getting consensus stats: {e}", exc_info=True)
            return {}


consensus_detector_instance = None

def get_consensus_detector(db: Database) -> ConsensusDetector:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞"""
    global consensus_detector_instance
    if consensus_detector_instance is None:
        consensus_detector_instance = ConsensusDetector(db)
    return consensus_detector_instance

================================================================================
File: tbot/analysis/message_parser.py
================================================================================
import re
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

from .pattern_manager import PatternManager

logger = logging.getLogger(__name__)

@dataclass
class ParseResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    success: bool
    signal_data: Optional[Dict] = None
    error: Optional[str] = None
    confidence: float = 0.0


class MessageParser:
    """–ü–∞—Ä—Å–µ—Ä —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ –ë–î"""
    
    VERSION = "3.1.0"
    
    def __init__(self, db_manager=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
        
        Args:
            db_manager: Database instance –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ –ë–î
        """
        self.db_manager = db_manager
        
        if db_manager:
            self.pattern_manager = PatternManager(db_manager)
            logger.info(f"MessageParser v{self.VERSION} initialized with PatternManager (DB mode)")
        else:
            self.pattern_manager = None
            logger.warning(f"MessageParser v{self.VERSION} initialized WITHOUT database")
    
    def reload_patterns(self):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –ë–î"""
        if self.pattern_manager:
            self.pattern_manager.reload_patterns()
            logger.info("Patterns reloaded from database")
        else:
            logger.warning("Cannot reload patterns - no database connection")
    
    def parse_raw_message(self, raw_message: Dict) -> ParseResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            raw_message: —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            ParseResult: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        try:
            text = raw_message.get('text', '')
            if not text or not text.strip():
                return ParseResult(success=False, error="Empty message text")
            
            logger.debug(f"üìù Parsing message {raw_message.get('id')}")
            logger.debug(f"Original text: {text[:200]}")
            
            # –ò–ó–í–õ–ï–ö–ê–ï–ú –ê–í–¢–û–†–ê –ò–ó –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û –¢–ï–ö–°–¢–ê (–î–û –û–ß–ò–°–¢–ö–ò!)
            author = self._extract_author(text, raw_message.get('author_username'))
            logger.debug(f"üë§ Extracted author: {author}")
            
            # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è —Ö–µ—à—Ç–µ–≥–æ–≤
            cleaned_text = text.strip()
            
            if not self._is_trading_message(cleaned_text):
                return ParseResult(success=False, error="Not a trading message")
            
            ticker = self._extract_ticker(cleaned_text)
            if not ticker:
                return ParseResult(success=False, error="No ticker found")
            
            operation_type, direction = self._analyze_operation(cleaned_text)
            
            prices = self._extract_prices(cleaned_text)
            confidence = self._calculate_confidence(cleaned_text, ticker, direction, operation_type)
            
            signal_data = {
                'raw_message_id': raw_message['id'],
                'parser_version': self.VERSION,
                'timestamp': raw_message['timestamp'],
                'channel_id': raw_message['channel_id'],
                'author': author,
                'original_text': text,
                'ticker': ticker,
                'direction': direction,
                'signal_type': operation_type,
                'target_price': prices.get('target'),
                'stop_loss': prices.get('stop_loss'),
                'take_profit': prices.get('take_profit'),
                'confidence_score': confidence,
                'extracted_data': {
                    'cleaned_text': cleaned_text,
                    'operation_analysis': self._debug_operation_analysis(cleaned_text),
                    'all_tickers': self._extract_all_tickers(cleaned_text),
                    'all_prices': self._extract_all_numbers(cleaned_text),
                    'raw_message_id': raw_message['id']
                }
            }
            
            logger.info(f"‚úÖ Parsed message {raw_message['id']}: "
                       f"ticker={ticker}, direction={direction}, operation={operation_type}, "
                       f"author={author}, confidence={confidence}")
            
            return ParseResult(success=True, signal_data=signal_data, confidence=confidence)
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing message {raw_message.get('id')}: {e}", exc_info=True)
            return ParseResult(success=False, error=f"Exception: {str(e)}")
    
    def _clean_message_text(self, text: str) -> str:
        """
        –û—á–∏—Å—Ç–∫–∞ –º—É—Å–æ—Ä–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
        –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–ê –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        
        Args:
            text: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            str: –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not self.pattern_manager:
            return text.strip()
        
        cleaned = text
        
        # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        # garbage_patterns = self.pattern_manager.get_patterns('garbage')
        # for pattern in garbage_patterns:
        #     cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
        
        cleaned = re.sub(r'\n\s*\n', '\n', cleaned)
        cleaned = cleaned.strip()
        
        return cleaned
    
    def _is_trading_message(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã–º
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            bool: True –µ—Å–ª–∏ —Ç–æ—Ä–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        if not self.pattern_manager:
            return False
        
        trading_keywords = self.pattern_manager.get_patterns('trading_keyword')
        ticker_patterns = self.pattern_manager.get_patterns('ticker')
        
        has_keywords = any(re.search(pattern, text, re.IGNORECASE) for pattern in trading_keywords)
        has_ticker = any(re.search(pattern, text) for pattern in ticker_patterns)
        
        trading_emojis = ['üî•', 'üé™', 'üìà', 'üìâ', '‚≠ê']
        has_emoji = any(emoji in text for emoji in trading_emojis)
        
        result = has_keywords or has_ticker or has_emoji
        
        logger.debug(f"Trading check: keywords={has_keywords}, ticker={has_ticker}, "
                    f"emoji={has_emoji} -> {result}")
        
        return result
    
    def _extract_ticker(self, text: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–∫–µ—Ä–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Optional[str]: –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–∏–∫–µ—Ä –∏–ª–∏ None
        """
        if not self.pattern_manager:
            return None
        
        ticker_patterns = self.pattern_manager.get_patterns('ticker')
        
        for pattern in ticker_patterns:
            match = re.search(pattern, text)
            if match:
                ticker = match.group(1).upper()
                logger.debug(f"Found ticker: {ticker} with pattern: {pattern}")
                return ticker
        
        return None
    
    def _extract_all_tickers(self, text: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            List[str]: —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤
        """
        if not self.pattern_manager:
            return []
        
        ticker_patterns = self.pattern_manager.get_patterns('ticker')
        
        tickers = set()
        for pattern in ticker_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                ticker = match.upper()
                if 3 <= len(ticker) <= 6 and ticker.isalpha():
                    if ticker not in ['VIP', 'BOT', 'NEW', 'TOP', 'WIN', 'BUY', 'SELL']:
                        tickers.add(ticker)
        
        return list(tickers)
    
    def _analyze_operation(self, text: str) -> Tuple[str, str]:
        """
        –ê–Ω–∞–ª–∏–∑ –æ–ø–µ—Ä–∞—Ü–∏–∏ - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Tuple[str, str]: (operation_type, direction)
                operation_type: 'entry' | 'exit' | 'update'
                direction: 'long' | 'short' | 'mixed'
        """
        if not self.pattern_manager:
            return 'entry', 'mixed'
        
        exit_patterns = self.pattern_manager.get_patterns('operation_exit')
        
        for pattern in exit_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                logger.debug(f"Found exit pattern: {pattern} -> {match.group()}")
                
                if re.search(r'(?i)(–ª–æ–Ω–≥|long)', match.group()):
                    return 'exit', 'long'
                elif re.search(r'(?i)(—à–æ—Ä—Ç|short)', match.group()):
                    return 'exit', 'short'
                else:
                    return 'exit', 'mixed'
        
        long_patterns = self.pattern_manager.get_patterns('direction_long')
        short_patterns = self.pattern_manager.get_patterns('direction_short')
        
        for pattern in long_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                logger.debug(f"Found long entry pattern: {pattern}")
                return 'entry', 'long'
        
        for pattern in short_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                logger.debug(f"Found short entry pattern: {pattern}")
                return 'entry', 'short'
        
        if re.search(r'(?i)\b(–ª–æ–Ω–≥|long)\b', text):
            return 'entry', 'long'
        elif re.search(r'(?i)\b(—à–æ—Ä—Ç|short)\b', text):
            return 'entry', 'short'
        
        return 'entry', 'mixed'
    
    def _debug_operation_analysis(self, text: str) -> Dict:
        """
        –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–ø–µ—Ä–∞—Ü–∏–π
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Dict: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        """
        if not self.pattern_manager:
            return {}
        
        debug_info = {
            'exit_matches': [],
            'long_matches': [],
            'short_matches': [],
            'direction_words': []
        }
        
        exit_patterns = self.pattern_manager.get_patterns('operation_exit')
        for pattern in exit_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                debug_info['exit_matches'].append({'pattern': pattern, 'matches': matches})
        
        long_patterns = self.pattern_manager.get_patterns('direction_long')
        for pattern in long_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                debug_info['long_matches'].append({'pattern': pattern, 'matches': matches})
        
        short_patterns = self.pattern_manager.get_patterns('direction_short')
        for pattern in short_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                debug_info['short_matches'].append({'pattern': pattern, 'matches': matches})
        
        direction_words = re.findall(r'(?i)\b(–ª–æ–Ω–≥|—à–æ—Ä—Ç|long|short)\b', text)
        debug_info['direction_words'] = direction_words
        
        return debug_info
    
    def _extract_author(self, text: str, fallback: Optional[str] = None) -> str:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            fallback: –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
        Returns:
            str: –∏–º—è –∞–≤—Ç–æ—Ä–∞
        """
        if not self.pattern_manager:
            logger.warning("‚ö†Ô∏è No pattern_manager in _extract_author")
            return fallback or 'Unknown'
        
        author_patterns = self.pattern_manager.get_patterns('author')
        
        logger.debug(f"üîç Author patterns count: {len(author_patterns)}")
        logger.debug(f"üîç Text to search (first 150 chars): {text[:150]}")
        
        for i, pattern in enumerate(author_patterns):
            logger.debug(f"üîç Testing author pattern #{i+1}: {pattern}")
            try:
                match = re.search(pattern, text)
                if match:
                    # –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –ø–µ—Ä–≤—É—é –≥—Ä—É–ø–ø—É, –µ—Å–ª–∏ –µ—Å—Ç—å
                    if match.groups():
                        author = match.group(1)
                    else:
                        author = match.group()
                    
                    logger.info(f"‚úÖ Found author: '{author}' with pattern: {pattern}")
                    return author
                else:
                    logger.debug(f"‚ùå Pattern #{i+1} did not match")
            except Exception as e:
                logger.error(f"‚ùå Error testing pattern {pattern}: {e}")
                continue
        
        logger.warning(f"‚ö†Ô∏è No author found in text, using fallback: {fallback or 'Unknown'}")
        return fallback or 'Unknown'
    
    def _extract_prices(self, text: str) -> Dict[str, Optional[float]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            Dict: —Å–ª–æ–≤–∞—Ä—å —Å —Ü–µ–Ω–∞–º–∏
        """
        prices = {'target': None, 'stop_loss': None, 'take_profit': None}
        
        if not self.pattern_manager:
            return prices
        
        target_patterns = self.pattern_manager.get_patterns('price_target')
        stop_patterns = self.pattern_manager.get_patterns('price_stop')
        take_patterns = self.pattern_manager.get_patterns('price_take')
        
        price_pattern_groups = {
            'target': target_patterns,
            'stop_loss': stop_patterns,
            'take_profit': take_patterns
        }
        
        for price_type, patterns in price_pattern_groups.items():
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    try:
                        price_str = match.group(1) if match.groups() else match.group()
                        price = float(price_str.replace(',', '.'))
                        if 0.01 <= price <= 100000:
                            prices[price_type] = price
                            break
                    except (ValueError, IndexError):
                        continue
        
        return prices
    
    def _extract_all_numbers(self, text: str) -> List[float]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö —á–∏—Å–µ–ª –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            List[float]: —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª
        """
        numbers = []
        for match in re.finditer(r'\d+(?:[.,]\d+)?', text):
            try:
                number = float(match.group().replace(',', '.'))
                if 0.01 <= number <= 100000:
                    numbers.append(number)
            except ValueError:
                continue
        return numbers
    
    def _calculate_confidence(self, text: str, ticker: str, direction: str, operation: str) -> float:
        """
        –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø–∞—Ä—Å–∏–Ω–≥–µ
        
        Args:
            text: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            ticker: –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–∏–∫–µ—Ä
            direction: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            operation: —Ç–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            float: —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0.0 - 1.0)
        """
        confidence = 0.0
        
        if ticker:
            confidence += 0.4
        if direction and direction != 'mixed':
            confidence += 0.3
        if operation:
            confidence += 0.2
        
        if len(text.split()) > 3:
            confidence += 0.05
        if any(keyword in text.lower() for keyword in ['—Å–¥–µ–ª–∫–∞', '–ø–æ–∑–∏—Ü–∏—è', '—Å–∏–≥–Ω–∞–ª']):
            confidence += 0.05
        
        return min(confidence, 1.0)


class MessageParsingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    
    def __init__(self, db_manager, parser: MessageParser = None):
        """
        Args:
            db_manager: Database instance
            parser: MessageParser instance (—Å–æ–∑–¥–∞—Å—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω)
        """
        self.db = db_manager
        self.parser = parser or MessageParser(db_manager)
    
    def parse_message(self, message: Dict) -> ParseResult:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            message: –¥–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            ParseResult: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        return self.parser.parse_raw_message(message)

    def parse_all_unprocessed_messages(self, limit: Optional[int] = None) -> Dict:
        try:
            unprocessed = self._get_unprocessed_messages(limit)
            
            if not unprocessed:
                logger.info("No unprocessed messages found")
                return {
                    'total_processed': 0,
                    'successful_parses': 0,
                    'failed_parses': 0,
                    'trading_messages': 0,
                    'non_trading_messages': 0,
                    'errors': []
                }
            
            stats = {
                'total_processed': 0,
                'successful_parses': 0,
                'failed_parses': 0,
                'trading_messages': 0,
                'non_trading_messages': 0,
                'errors': []
            }
            
            logger.info(f"Starting to parse {len(unprocessed)} messages...")
            
            for message in unprocessed:
                try:
                    stats['total_processed'] += 1
                    
                    result = self.parser.parse_raw_message(message)
                    
                    if result.success:
                        signal_id = self.db.save_signal(result.signal_data)
                        if signal_id:
                            stats['successful_parses'] += 1
                            stats['trading_messages'] += 1
                            self.db.mark_message_processed(message['id'], parse_success=True)
                        else:
                            stats['failed_parses'] += 1
                            self.db.mark_message_processed(message['id'], parse_success=False)
                    else:
                        stats['failed_parses'] += 1
                        if result.error != "Not a trading message":
                            stats['errors'].append({
                                'message_id': message['id'],
                                'error': result.error
                            })
                        else:
                            stats['non_trading_messages'] += 1
                        
                        self.db.mark_message_processed(message['id'], parse_success=False)
                    
                except Exception as e:
                    logger.error(f"Error processing message {message.get('id')}: {e}")
                    stats['errors'].append({
                        'message_id': message.get('id'),
                        'error': str(e)
                    })
                    self.db.mark_message_processed(message.get('id'), parse_success=False)
            
            logger.info(f"Parsing completed: {stats['successful_parses']} successful, "
                    f"{stats['failed_parses']} failed")
            
            return stats
            
        except Exception as e:
            logger.error(f"Failed to parse messages: {e}")
            return {
                'total_processed': 0,
                'successful_parses': 0,
                'failed_parses': 0,
                'errors': [{'error': str(e)}]
            }

    def _get_unprocessed_messages(self, limit: Optional[int]) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ë–î"""
        messages = self.db.get_unparsed_messages(limit=limit or 100)
        return messages

================================================================================
File: tbot/analysis/pattern_manager.py
================================================================================
"""
Pattern Manager - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑ –ë–î
"""
import re
import logging
from typing import Dict, List, Optional
from functools import lru_cache

logger = logging.getLogger(__name__)

class PatternManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    
    def __init__(self, db_manager):
        """
        Args:
            db_manager: Database instance
        """
        self.db = db_manager
        self._cache = {}
        self._cache_loaded = False
        
        logger.info("PatternManager initialized")
    
    def reload_patterns(self) -> None:
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –ë–î (–æ—á–∏—Å—Ç–∏—Ç—å –∫–µ—à)"""
        self._cache.clear()
        self._cache_loaded = False
        logger.info("Pattern cache cleared, will reload on next access")
    
    def _load_all_patterns(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –ë–î –≤ –∫–µ—à"""
        if self._cache_loaded:
            return
        
        try:
            all_patterns = self.db.get_all_patterns(active_only=True)
            
            for pattern_data in all_patterns:
                category = pattern_data['category']
                if category not in self._cache:
                    self._cache[category] = []
                
                self._cache[category].append({
                    'id': pattern_data['id'],
                    'name': pattern_data['name'],
                    'pattern': pattern_data['pattern'],
                    'priority': pattern_data['priority']
                })
            
            for category in self._cache:
                self._cache[category].sort(key=lambda x: x['priority'], reverse=True)
            
            self._cache_loaded = True
            logger.info(f"Loaded {len(all_patterns)} patterns into cache")
            
        except Exception as e:
            logger.error(f"Failed to load patterns from DB: {e}")
            self._cache_loaded = False
    
    def get_patterns(self, category: str) -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        
        Args:
            category: –∫–∞—Ç–µ–≥–æ—Ä–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            
        Returns:
            List[str]: —Å–ø–∏—Å–æ–∫ regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        """
        self._load_all_patterns()
        
        patterns = self._cache.get(category, [])
        return [p['pattern'] for p in patterns]
    
    def get_patterns_by_categories(self, categories: List[str]) -> Dict[str, List[str]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        
        Args:
            categories: —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            
        Returns:
            Dict: —Å–ª–æ–≤–∞—Ä—å {–∫–∞—Ç–µ–≥–æ—Ä–∏—è: [–ø–∞—Ç—Ç–µ—Ä–Ω—ã]}
        """
        self._load_all_patterns()
        
        result = {}
        for category in categories:
            result[category] = self.get_patterns(category)
        
        return result
    
    def test_pattern(self, pattern: str, text: str) -> List[Dict]:
        """
        –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–∞ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            pattern: regex –ø–∞—Ç—Ç–µ—Ä–Ω
            text: —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            List[Dict]: —Å–ø–∏—Å–æ–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        """
        try:
            matches = []
            for match_obj in re.finditer(pattern, text, re.IGNORECASE):
                matches.append({
                    'match': match_obj.group(),
                    'start': match_obj.start(),
                    'end': match_obj.end(),
                    'groups': match_obj.groups()
                })
            return matches
        except re.error as e:
            logger.error(f"Invalid regex pattern: {e}")
            return []
    
    def get_cache_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–µ—à–∞"""
        return {
            'cache_loaded': self._cache_loaded,
            'categories_count': len(self._cache),
            'total_patterns': sum(len(patterns) for patterns in self._cache.values()),
            'categories': {
                cat: len(patterns) 
                for cat, patterns in self._cache.items()
            }
        }

================================================================================
File: tbot/analysis/signal_matcher.py
================================================================================
# analysis/signal_matcher.py - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
import logging
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta, timezone  # ‚úÖ –î–û–ë–ê–í–ò–õ–ò timezone
from dataclasses import dataclass
from utils.datetime_utils import now_utc, utc_from_minutes_ago, ensure_timezone_aware, days_between_utc
from core.database import Database
from core.database import ParsedSignal, SignalResult, ChartDataPoint

logger = logging.getLogger(__name__)

@dataclass
class PriceMatch:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞ —Å —Ü–µ–Ω–æ–π"""
    signal_id: str
    signal_time: datetime
    target_price: Optional[float]
    actual_price: float
    price_time: datetime
    slippage_pct: float
    delay_minutes: int

class SignalMatcher:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —Å —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏ + Tinkoff API"""
    
    def __init__(self, db_manager: Database, tinkoff_client=None):
        self.db = db_manager
        self.tinkoff = tinkoff_client 
        self.tracking_timeout_hours = 24
        
    # ===== –û–ë–ù–û–í–õ–ï–ù–ù–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° TINKOFF API =====

    async def _find_entry_price(self, signal: Dict, figi: str) -> Optional[PriceMatch]:
        """
        üîÑ –û–ë–ù–û–í–õ–ï–ù–û: –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã –≤—Ö–æ–¥–∞ –¥–ª—è —Å–∏–≥–Ω–∞–ª–∞ (–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö + API)
        """
        try:
            signal_time = ensure_timezone_aware(signal['timestamp'])  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            search_end = signal_time + timedelta(hours=1)
            
            # ‚ú® –°–ù–ê–ß–ê–õ–ê –ü–´–¢–ê–ï–ú–°–Ø –ù–ê–ô–¢–ò –í –ë–ê–ó–ï –î–ê–ù–ù–´–•
            candles = self.db.get_candles(
                figi,  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±—Ä–∞–ª–∏ instrument_id=
                interval='5min',  # üîÑ –ò–ó–ú–ï–ù–ï–ù–û: 5min –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
                from_time=signal_time,
                to_time=search_end,
                limit=12  # 12 —Å–≤–µ—á–µ–π –ø–æ 5 –º–∏–Ω = 1 —á–∞—Å
            )
            
            if candles:
                # –ù–∞—à–ª–∏ –≤ –±–∞–∑–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ —Ä–∞–Ω—å—à–µ
                first_candle = candles[0]
                entry_price = first_candle['open']
                entry_time = ensure_timezone_aware(first_candle['time'])  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                
                logger.info(f"üíæ Found entry price in database: {entry_price} for {signal['ticker']}")
                
            else:
                # ‚ú® –ù–ï–¢ –í –ë–ê–ó–ï - –ò–°–ü–û–õ–¨–ó–£–ï–ú API
                if not self.tinkoff:
                    logger.error("‚ùå No DB data and Tinkoff API not available")
                    return None
                
                logger.info(f"üåê Getting entry price via API for {signal['ticker']}")
                price_data = await self.tinkoff.get_current_price(signal['ticker'])
                
                if not price_data:
                    return None
                
                entry_price = price_data['price']
                entry_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: timezone-aware
                
                logger.info(f"üåê Entry price via API: {entry_price}")
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏–µ
            target_price = signal.get('target_price')
            slippage_pct = 0.0
            
            if target_price:
                slippage_pct = ((entry_price - target_price) / target_price) * 100
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–∏
            delay_minutes = int((entry_time - signal_time).total_seconds() / 60)
            
            return PriceMatch(
                signal_id=signal['id'],
                signal_time=signal_time,
                target_price=target_price,
                actual_price=entry_price,
                price_time=entry_time,
                slippage_pct=slippage_pct,
                delay_minutes=delay_minutes
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error finding entry price: {e}")
            return None

    async def _check_exit_conditions(self, position: Dict, signal: Dict, figi: str) -> Optional[Dict]:
        """
        üîÑ –û–ë–ù–û–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –≤—ã—Ö–æ–¥–∞ (–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö + API)
        """
        try:
            current_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: timezone-aware
            direction = signal['direction']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É
            current_price = await self._get_current_price(figi, signal['ticker'])
            if not current_price:
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º stop-loss
            if signal.get('stop_loss'):
                stop_loss = float(signal['stop_loss'])
                if direction == 'long' and current_price <= stop_loss:
                    return {'price': current_price, 'time': current_time, 'reason': 'stop_loss'}
                elif direction == 'short' and current_price >= stop_loss:
                    return {'price': current_price, 'time': current_time, 'reason': 'stop_loss'}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º take-profit
            if signal.get('take_profit'):
                take_profit = float(signal['take_profit'])
                if direction == 'long' and current_price >= take_profit:
                    return {'price': current_price, 'time': current_time, 'reason': 'take_profit'}
                elif direction == 'short' and current_price <= take_profit:
                    return {'price': current_price, 'time': current_time, 'reason': 'take_profit'}
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error checking exit conditions: {e}")
            return None

    async def _get_current_price(self, figi: str, ticker: str = None) -> Optional[float]:
        """
        üîÑ –û–ë–ù–û–í–õ–ï–ù–û: –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã (–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö + API)
        """
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –±–∞–∑—ã
            candles = self.db.get_candles(
                figi,  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±—Ä–∞–ª–∏ instrument_id=
                interval='5min',  # üîÑ –ò–ó–ú–ï–ù–ï–ù–û: 5min
                from_time=utc_from_minutes_ago(25),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: timezone-aware
                limit=1
            )
            
            if candles:
                price = candles[0]['close']
                logger.debug(f"üíæ Current price from DB: {price}")
                return float(price)
            
            # üÜï –ù–ï–¢ –í –ë–ê–ó–ï - –ü–´–¢–ê–ï–ú–°–Ø –ß–ï–†–ï–ó API
            if self.tinkoff:
                logger.debug(f"üåê Getting current price via API for {ticker or figi}")
                price_data = await self.tinkoff.get_current_price(ticker or figi)
                
                if price_data and 'price' in price_data:
                    price = float(price_data['price'])
                    logger.debug(f"üåê Current price from API: {price}")
                    return price
            
            logger.warning(f"‚ö†Ô∏è No price data available for {ticker or figi}")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error getting current price: {e}")
            return None
    # ===== –ù–û–í–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° TINKOFF =====
    
    async def ensure_instrument_in_database(self, ticker: str) -> Optional[str]:
        """
        ‚ú® –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –µ—Å—Ç—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            # –ò—â–µ–º –≤ –±–∞–∑–µ
            instrument = self.db.get_instrument_by_ticker(ticker)
            if instrument:
                return instrument['figi']
            
            # –ù–µ—Ç –≤ –±–∞–∑–µ - –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ API
            if not self.tinkoff:
                logger.error(f"‚ùå Instrument {ticker} not in DB and no API available")
                return None
            
            logger.info(f"üîç Searching instrument {ticker} via API...")
            api_instrument = await self.tinkoff.find_instrument_by_ticker(ticker)
            
            if not api_instrument:
                logger.error(f"‚ùå Instrument {ticker} not found via API")
                return None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
            self.db.save_instrument(
                figi=api_instrument["figi"],
                ticker=ticker,
                name=api_instrument["name"],
                instrument_type=api_instrument.get("type", "share")
            )
            
            logger.info(f"‚úÖ Added instrument {ticker} to database")
            return api_instrument["figi"]
            
        except Exception as e:
            logger.error(f"‚ùå Error ensuring instrument {ticker} in database: {e}")
            return None
    
    async def process_untracked_signals(self, limit: int = 50) -> int:
        """
        üîÑ –û–ë–ù–û–í–õ–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
        """
        try:
            untracked_signals = self._get_untracked_signals(limit)
            processed = 0
            
            for signal in untracked_signals:
                try:
                    figi = await self.ensure_instrument_in_database(signal['ticker'])
                    if not figi:
                        logger.warning(f"‚ö†Ô∏è Cannot process signal - instrument {signal['ticker']} not available")
                        continue
                    
                    # –ù–∞—Ö–æ–¥–∏–º —Ü–µ–Ω—É –≤—Ö–æ–¥–∞ (—Ç–µ–ø–µ—Ä—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π API)
                    entry_match = await self._find_entry_price(signal, figi)
                    if entry_match:
                        result_data = {
                            'planned_entry_price': signal.get('target_price'),
                            'actual_entry_price': entry_match.actual_price,
                            'entry_time': entry_match.price_time,
                            'status': 'active'
                        }
                        result_id = self.db.save_signal_result(signal['id'], result_data)
                        
                        if result_id:
                            processed += 1
                            logger.info(f"‚úÖ Started tracking signal {signal['id']}: {signal['ticker']} "
                                      f"@ {entry_match.actual_price}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error processing signal {signal['id']}: {e}")
                    continue
            
            logger.info(f"üìä Started tracking {processed} new signals")
            return processed
            
        except Exception as e:
            logger.error(f"‚ùå Error in process_untracked_signals: {e}")
            return 0

    async def update_active_positions(self) -> int:
        """
        üîÑ –û–ë–ù–û–í–õ–ï–ù–û: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤—ã—Ö–æ–¥–æ–≤
        """
        try:
            active_positions = self._get_active_positions()
            updated = 0
            
            logger.info(f"üìä Checking {len(active_positions)} active positions...")
            
            for position in active_positions:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏–≥–Ω–∞–ª–µ
                    signal = self._get_signal_by_id(position['signal_id'])
                    if not signal:
                        continue
                    
                    # ‚ú® –£–ë–ï–ñ–î–ê–ï–ú–°–Ø –ß–¢–û –ò–ù–°–¢–†–£–ú–ï–ù–¢ –ï–°–¢–¨ –í –ë–ê–ó–ï
                    figi = await self.ensure_instrument_in_database(signal['ticker'])
                    if not figi:
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ (—Ç–µ–ø–µ—Ä—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π API)
                    exit_result = await self._check_exit_conditions(position, signal, figi)
                    
                    if exit_result:
                        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é
                        self.db.update_signal_result(
                            position['id'],  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: result_id
                            {  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: updates –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å
                                'exit_price': exit_result['price'],
                                'exit_time': exit_result['time'],
                                'exit_reason': exit_result['reason'],
                                'status': 'closed'
                            }
                        )
                        updated += 1
                        logger.info(f"‚úÖ Closed position {position['signal_id']}: "
                                f"{exit_result['reason']} @ {exit_result['price']}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∞–π–º–∞—É—Ç
                    elif self._is_position_expired(position):
                        current_price = await self._get_current_price(figi, signal['ticker'])
                        if current_price:
                            self.db.update_signal_result(
                                position['id'],  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: result_id  
                                {  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: updates –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å
                                    'exit_price': current_price,
                                    'exit_time': now_utc(),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
                                    'exit_reason': 'timeout',
                                    'status': 'closed'
                                }
                            )
                            updated += 1
                            logger.info(f"‚è∞ Closed expired position {position['signal_id']} @ {current_price}")
                
                except Exception as e:
                    logger.error(f"‚ùå Error updating position {position['signal_id']}: {e}")
                    continue
            
            logger.info(f"üìà Updated {updated} active positions")
            return updated
            
        except Exception as e:
            logger.error(f"‚ùå Error in update_active_positions: {e}")
            return 0    

    # ===== –û–°–¢–ê–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ –û–°–¢–ê–Æ–¢–°–Ø –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô =====
    
    def _get_untracked_signals(self, limit: int) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)"""
        try:
            with self.db.session() as session:
                # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º timezone-aware –¥–∞—Ç—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                from_date = now_utc() - timedelta(days=7)
                
                signals = session.query(ParsedSignal).outerjoin(SignalResult).filter(
                    SignalResult.id.is_(None),
                    ParsedSignal.direction.in_(['long', 'short']),
                    ParsedSignal.timestamp >= from_date
                ).order_by(ParsedSignal.timestamp).limit(limit).all()
                
                return [
                    {
                        'id': str(signal.id),
                        'ticker': signal.ticker,
                        'direction': signal.direction,
                        'target_price': float(signal.target_price) if signal.target_price else None,
                        'timestamp': signal.timestamp,
                        'trader': signal.author
                    }
                    for signal in signals
                ]
        except Exception as e:
            logger.error(f"‚ùå Error getting untracked signals: {e}")
        return []
    
    def _get_active_positions(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)"""
        try:
            with self.db.session() as session:
                results = session.query(SignalResult).filter(
                    SignalResult.status == 'active'
                ).all()
                
                return [
                    {
                        'id': str(result.id),
                        'signal_id': str(result.signal_id),
                        'entry_price': float(result.actual_entry_price),
                        'entry_time': result.entry_time,
                        'tracking_started_at': result.tracking_started_at
                    }
                    for result in results
                ]
        except Exception as e:
            logger.error(f"‚ùå Error getting active positions: {e}")
            return []
    
    def _get_signal_by_id(self, signal_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ ID (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)"""
        try:
            with self.db.session() as session:
                signal = session.query(ParsedSignal).filter(
                    ParsedSignal.id == signal_id
                ).first()
                
                if not signal:
                    return None
                
                return {
                    'id': str(signal.id),
                    'ticker': signal.ticker,
                    'direction': signal.direction,
                    'target_price': float(signal.target_price) if signal.target_price else None,
                    'stop_loss': float(signal.stop_loss) if signal.stop_loss else None,
                    'take_profit': float(signal.take_profit) if signal.take_profit else None,
                    'timestamp': signal.timestamp,
                    'trader': signal.author
                }
        except Exception as e:
            logger.error(f"‚ùå Error getting signal {signal_id}: {e}")
            return None
    
    def _is_position_expired(self, position: Dict) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏—Å—Ç–µ—á–µ–Ω–∏–µ —Å—Ä–æ–∫–∞ –ø–æ–∑–∏—Ü–∏–∏
        """
        try:
            tracking_started = ensure_timezone_aware(position['tracking_started_at'])  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            current_time = now_utc()  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û
            
            hours_tracked = (current_time - tracking_started).total_seconds() / 3600
            return hours_tracked >= self.tracking_timeout_hours
            
        except Exception as e:
            logger.error(f"‚ùå Error checking position expiry: {e}")
            return False

================================================================================
File: tbot/utils/datetime_utils.py
================================================================================
# utils/datetime_utils.py
"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞–º–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∑–æ–Ω–∞–º–∏
–í—Å–µ –¥–∞—Ç—ã –≤ —Å–∏—Å—Ç–µ–º–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ UTC –∫–∞–∫ –ø—Ä–∏—Ö–æ–¥—è—Ç –æ—Ç Tinkoff API
"""

from datetime import datetime, timezone, timedelta
from typing import Optional, Union
import logging

logger = logging.getLogger(__name__)

def now_utc() -> datetime:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ UTC —Å timezone
    
    Returns:
        datetime: –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ UTC timezone-aware
    """
    return datetime.now(timezone.utc)

def ensure_timezone_aware(dt: Union[datetime, None]) -> Optional[datetime]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç naive datetime –≤ UTC aware –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None
    
    Args:
        dt: datetime –æ–±—ä–µ–∫—Ç –∏–ª–∏ None
        
    Returns:
        datetime: timezone-aware datetime –≤ UTC –∏–ª–∏ None
    """
    if dt is None:
        return None
        
    if dt.tzinfo is None:
        # –ï—Å–ª–∏ timezone –Ω–µ —É–∫–∞–∑–∞–Ω, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —ç—Ç–æ UTC
        logger.debug(f"Converting naive datetime {dt} to UTC")
        return dt.replace(tzinfo=timezone.utc)
    
    return dt

def utc_from_days_ago(days: int) -> datetime:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç—É N –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –≤ UTC timezone-aware
    
    Args:
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥
        
    Returns:
        datetime: –î–∞—Ç–∞ –≤ UTC timezone-aware
    """
    return now_utc() - timedelta(days=days)

def utc_from_minutes_ago(minutes: int) -> datetime:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç—É N –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥ –≤ UTC timezone-aware
    
    Args:
        minutes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥
        
    Returns:
        datetime: –î–∞—Ç–∞ –≤ UTC timezone-aware
    """
    return now_utc() - timedelta(minutes=minutes)

def days_between_utc(start_dt: datetime, end_dt: datetime) -> int:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –º–µ–∂–¥—É –¥–≤—É–º—è UTC –¥–∞—Ç–∞–º–∏
    
    Args:
        start_dt: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å timezone-aware)
        end_dt: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å timezone-aware)
        
    Returns:
        int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
    """
    # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —á—Ç–æ –æ–±–µ –¥–∞—Ç—ã timezone-aware
    start_dt = ensure_timezone_aware(start_dt)
    end_dt = ensure_timezone_aware(end_dt)
    
    if start_dt is None or end_dt is None:
        return 0
        
    return (end_dt - start_dt).days

def is_timezone_aware(dt: datetime) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ datetime timezone-aware
    
    Args:
        dt: datetime –æ–±—ä–µ–∫—Ç
        
    Returns:
        bool: True –µ—Å–ª–∏ timezone-aware
    """
    return dt.tzinfo is not None and dt.tzinfo.utcoffset(dt) is not None


=== –ö–û–î –û–ë–†–´–í–ê–ï–¢–°–Ø. –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –í –°–õ–ï–î–£–Æ–©–ï–ú –§–ê–ô–õ–ï ===

